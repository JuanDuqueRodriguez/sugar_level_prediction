{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "seq2seq_prediction_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSmCiYhICymz",
        "colab_type": "text"
      },
      "source": [
        "# Sequence to Sequence models for sugar level prediction\n",
        "\n",
        "For the first part, which make use of Recurrent Neural Networks, \n",
        "take a look at https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
        "\n",
        "The second part (to be done) will use the more advanced Transformer arquitecture. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bf6QtFIDWP_",
        "colab_type": "code",
        "outputId": "239bcb9f-7ac0-4578-b40c-a18449bb1bd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNKe6wt8Cym-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZTMhkmyDR0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, LSTM, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import MAE\n",
        "from tensorflow.keras.metrics import MAPE, MSE\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.constraints import max_norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiR37YAS-I4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_train_history(history, title):\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(loss))\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "  plt.title(title)\n",
        "  plt.legend()\n",
        "\n",
        "  plt.yscale('log')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2vCNO9-PfN3",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3KZB7NjEIl0",
        "colab_type": "text"
      },
      "source": [
        "### Load datasets\n",
        "\n",
        "Each dataset consits of sequences of `history`+`future` points, with 4 features: \n",
        "\n",
        "* time interval: days counted starting from the end of the `history` of the sequence. Thus, for points in the `history`, this feature takes negatuve values, while for points in the `future`, it's positive. \n",
        "* hour: hour of the day, divided by 24.\n",
        "* day of week: day of the week in numbers ('Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6), divided by 7.\n",
        "* sugar level: recorded sugar level, scaled with min/max scaler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRgpiZSoEH2x",
        "colab_type": "code",
        "outputId": "e77217a8-dc68-48aa-9ee7-6f65e9c233cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRcQBJPOESsA",
        "colab_type": "code",
        "outputId": "239a8f5c-270c-4a82-de36-ef5215360a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!ls '/content/drive/My Drive/Colab Notebooks/sugar_level_prediction/data/'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "noisy0.0_test.npy   noisy0.0_vad.npy\n",
            "noisy0.0_train.npy  patient_measurements.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vdrtT6jCynO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = \"/content/drive/My Drive/Colab Notebooks/sugar_level_prediction/data/\"\n",
        "noise=0.0\n",
        "history = 100 \n",
        "future = 12\n",
        "\n",
        "train = np.load(os.path.join(root, \"noisy%s_train.npy\" %noise))\n",
        "vad = np.load(os.path.join(root, \"noisy%s_vad.npy\" %noise))\n",
        "test = np.load(os.path.join(root, \"noisy%s_test.npy\" %noise))\n",
        "\n",
        "train_batch = 200\n",
        "vad_batch = 200\n",
        "test_batch = 200\n",
        "num_epochs = 5\n",
        "\n",
        "train_steps = train.shape[0] // train_batch\n",
        "vad_steps = vad.shape[0] // train_batch\n",
        "test_steps = test.shape[0] // test_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifC3ViJVCynb",
        "colab_type": "code",
        "outputId": "6c2951e3-d66a-4487-dd51-89af3afb4e53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train.shape, vad.shape, test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((70487, 112, 4), (9116, 112, 4), (8781, 112, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGcDkv-LJWUw",
        "colab_type": "text"
      },
      "source": [
        "###  Split data \n",
        "\n",
        "Each input sequence has both the features and labels (x and y, if you wish), so we have to separate them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk_8mzP9JrcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_features_labels(data, history, future):\n",
        "    \"\"\"\n",
        "    Method to separate historic and future events (features and labels). \n",
        "    It returns input data for the encoder and decoder, and the output data \n",
        "    for the decoder. The input data for the decoder is just the output data \n",
        "    of the decoder, shifted by one step. \n",
        "\n",
        "    :param data: numpy ndarray with sequences of history+future points, and 4 attributes \n",
        "      (time_interval, hour_of_day, day_of_week, sugar_level). It has shape (?, history+future, 4)\n",
        "    :param history: number of points for the features\n",
        "    :param future: number of points for the labels\n",
        "    :return three numpy arrays with the input data for the encoder (shape=(?, history, 4))\n",
        "        and decoder (shape=(?, future+1, 1)), and the output data for the decoder\n",
        "        (shape=(?, future+1, 1))\n",
        "    \"\"\"\n",
        "    # split features and labels . Note that for the later, we only keep the \n",
        "    # feature with the sugar level, which constitutes our target\n",
        "    yf, yl = data[:, :history], data[:, history:history+future, -1]\n",
        "    \n",
        "    # add start of sentence to labels (input to the decoder)\n",
        "    yl_input = np.zeros(shape=(yl.shape[0], yl.shape[1]+1))\n",
        "    yl_input[:, 1:] = yl\n",
        "    # add end of sentence to labels (output of the decoder)\n",
        "    yl_output = np.zeros(shape=(yl.shape[0], yl.shape[1]+1))\n",
        "    yl_output[:, :-1] = yl\n",
        "    \n",
        "    # add new dimension at the end of input/output arrays to the decoder\n",
        "    yl_input = yl_input[:, :, np.newaxis].astype(np.float32)\n",
        "    yl_output = yl_output[:, :, np.newaxis].astype(np.float32)\n",
        "    \n",
        "    return (yf, yl_input), yl_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE0-L8XQObFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = split_features_labels(train, history, future)\n",
        "vad_data = split_features_labels(vad, history, future)\n",
        "test_data = split_features_labels(test, history, future)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26Ib_uLdCyns",
        "colab_type": "code",
        "outputId": "10c4adf8-b163-49db-926a-a5d9f9d56cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_data[0][0].shape, train_data[0][1].shape, train_data[1].shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((70487, 100, 4), (70487, 13, 1), (70487, 13, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGsfNjwfCyny",
        "colab_type": "text"
      },
      "source": [
        "### Make generators to feed the NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kSk9B0EPRkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(tensor):\n",
        "    return tf.data.Dataset.from_tensor_slices(tensor)\n",
        "\n",
        "def make_iterator(tensor, batch_size, num_epochs):\n",
        "    dataset = make_dataset(tensor)\n",
        "    return dataset.batch(batch_size).repeat(num_epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-QOHu8yPTh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gen = make_iterator(train_data, train_batch, num_epochs)\n",
        "vad_gen = make_iterator(vad_data, vad_batch, num_epochs=1)\n",
        "test_gen = make_iterator(test_data, test_batch, num_epochs=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuVvMSenPYj8",
        "colab_type": "text"
      },
      "source": [
        "## Seq2seq model with RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeDOOy49Cyn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(latent_dim, num_features, mn):\n",
        "    \"\"\"\n",
        "    Encoder with LSTM \n",
        "\n",
        "    :param latent_dim: dimension of the encoding vectors\n",
        "    :param num_features: number of input features\n",
        "    :param mn: max norm value\n",
        "    :return encoder input and output states, and the inference model\n",
        "    \"\"\"\n",
        "    # Define an input sequence and process it.\n",
        "    encoder_inputs = Input(shape=(None, num_features))\n",
        "    lstm_enc1 = LSTM(latent_dim, return_sequences=True, kernel_constraint=max_norm(mn))(encoder_inputs)\n",
        "    encoder = LSTM(latent_dim, return_state=True, kernel_constraint=max_norm(mn))\n",
        "    _, state_h, state_c = encoder(lstm_enc1)\n",
        "    # We discard `encoder_outputs` and only keep the states.\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    # model to perform inference with the encoder\n",
        "    encoder_model = Model(inputs=encoder_inputs, \n",
        "                          outputs=encoder_states, \n",
        "                          name='encoder_model_inference')\n",
        "\n",
        "    return encoder_inputs, encoder_states, encoder_model\n",
        "\n",
        "def decoder(encoder_states, latent_dim, mn):\n",
        "    \"\"\"\n",
        "    Decoder with LSTM \n",
        "    \n",
        "    :param encoder_satates: list of tensors with the LSTM states (cell and hidden)\n",
        "    :param latent_dim: dimension of the decoding vectors\n",
        "    :param mn: max norm value\n",
        "    :return decoder input and output sequences, and the inference model\n",
        "    \"\"\"\n",
        "    # Define an input sequence and process it.\n",
        "    # Set up the decoder, using `encoder_states` as initial state.\n",
        "    decoder_inputs = Input(shape=(None, 1))\n",
        "    # We set up our decoder to return full output sequences,\n",
        "    # and to return internal states as well. We don't use the \n",
        "    # return states in the training model, but we will use them in inference.\n",
        "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, \n",
        "                        kernel_constraint=max_norm(mn))\n",
        "    lstm_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "    decoder_dense = Dense(1, activation='selu', kernel_constraint=max_norm(mn))\n",
        "    decoder_outputs = decoder_dense(lstm_outputs)\n",
        "\n",
        "    # model to perform inference with the decoder\n",
        "\n",
        "    # inputs to cell and state (to be feed from the encoder last states, or others!)\n",
        "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "    decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    decoder_outputs_inference, state_h, state_c = decoder_lstm(\n",
        "        decoder_inputs, initial_state=decoder_states_inputs)\n",
        "    \n",
        "    decoder_states_inference = [state_h, state_c]\n",
        "    decoder_outputs_inference = decoder_dense(decoder_outputs_inference)\n",
        "    decoder_model = Model(\n",
        "        inputs=[decoder_inputs] + decoder_states_inputs,\n",
        "        outputs=[decoder_outputs_inference] + decoder_states_inference,\n",
        "        name='decoder_model_inference')\n",
        "    \n",
        "    return decoder_inputs, decoder_outputs, decoder_model\n",
        "\n",
        "def seq2seq(history, future, latent_dim, num_features, mn):\n",
        "    \"\"\"\n",
        "\n",
        "    :param history: number of steps of input sequence\n",
        "    :param future: number of steps of output sequence\n",
        "    :param latent_dim: dimension of the encoding/decoding vectors\n",
        "    :param num_features: number of input features\n",
        "    :param mn: max norm value\n",
        "    :return the model\n",
        "    \"\"\"\n",
        "    clear_session()\n",
        "\n",
        "    # encode\n",
        "    encoder_inputs, encoder_states, encoder_model = encoder(latent_dim, num_features, mn)\n",
        "    print(encoder_model.summary())\n",
        "\n",
        "    # decode\n",
        "    decoder_inputs, decoder_outputs, decoder_model = decoder(encoder_states, latent_dim, mn)\n",
        "    print(decoder_model.summary())\n",
        "\n",
        "    # Training model\n",
        "    training_model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
        "                           outputs=decoder_outputs, \n",
        "                           name='seq2seq_training_model')\n",
        "    print(training_model.summary())\n",
        "\n",
        "    return training_model, encoder_model, decoder_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLPoxD0V42jE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a74dd2f8-0d1d-4b45-b8f8-8878c547e927"
      },
      "source": [
        "m, enc, dec = seq2seq(history, future, latent_dim=50, num_features=4, mn=1.0)\n",
        "m.compile(optimizer='rmsprop', loss=MAE, metrics=[MSE])\n",
        "h = m.fit(x=train_data[0], y=train_data[1], batch_size=train_batch, epochs=50, \n",
        "          validation_data=vad_data)\n",
        "plot_train_history(h, 'Seq2Seq 50 dimensions')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_model_inference\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, 4)]         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 50)          11000     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                [(None, 50), (None, 50),  20200     \n",
            "=================================================================\n",
            "Total params: 31,200\n",
            "Trainable params: 31,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"decoder_model_inference\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 50), ( 10400       input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 1)      51          lstm_2[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"seq2seq_training_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 4)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, None, 50)     11000       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 50), (None,  20200       lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 50), ( 10400       input_2[0][0]                    \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 1)      51          lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 41,651\n",
            "Trainable params: 41,651\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 70487 samples, validate on 9116 samples\n",
            "Epoch 1/50\n",
            "70487/70487 [==============================] - 15s 215us/sample - loss: 0.1293 - mean_squared_error: 0.0353 - val_loss: 0.0815 - val_mean_squared_error: 0.0139\n",
            "Epoch 2/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0681 - mean_squared_error: 0.0100 - val_loss: 0.0572 - val_mean_squared_error: 0.0066\n",
            "Epoch 3/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0503 - mean_squared_error: 0.0054 - val_loss: 0.0480 - val_mean_squared_error: 0.0045\n",
            "Epoch 4/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0423 - mean_squared_error: 0.0041 - val_loss: 0.0364 - val_mean_squared_error: 0.0026\n",
            "Epoch 5/50\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0378 - mean_squared_error: 0.0035 - val_loss: 0.0326 - val_mean_squared_error: 0.0021\n",
            "Epoch 6/50\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0348 - mean_squared_error: 0.0031 - val_loss: 0.0310 - val_mean_squared_error: 0.0019\n",
            "Epoch 7/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0329 - mean_squared_error: 0.0030 - val_loss: 0.0311 - val_mean_squared_error: 0.0020\n",
            "Epoch 8/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0317 - mean_squared_error: 0.0028 - val_loss: 0.0282 - val_mean_squared_error: 0.0017\n",
            "Epoch 9/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0309 - mean_squared_error: 0.0028 - val_loss: 0.0269 - val_mean_squared_error: 0.0017\n",
            "Epoch 10/50\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0303 - mean_squared_error: 0.0027 - val_loss: 0.0267 - val_mean_squared_error: 0.0016\n",
            "Epoch 11/50\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0297 - mean_squared_error: 0.0026 - val_loss: 0.0317 - val_mean_squared_error: 0.0020\n",
            "Epoch 12/50\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0294 - mean_squared_error: 0.0026 - val_loss: 0.0278 - val_mean_squared_error: 0.0017\n",
            "Epoch 13/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0288 - mean_squared_error: 0.0025 - val_loss: 0.0275 - val_mean_squared_error: 0.0017\n",
            "Epoch 14/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0287 - mean_squared_error: 0.0025 - val_loss: 0.0264 - val_mean_squared_error: 0.0016\n",
            "Epoch 15/50\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0283 - mean_squared_error: 0.0024 - val_loss: 0.0285 - val_mean_squared_error: 0.0018\n",
            "Epoch 16/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0280 - mean_squared_error: 0.0023 - val_loss: 0.0268 - val_mean_squared_error: 0.0016\n",
            "Epoch 17/50\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0277 - mean_squared_error: 0.0023 - val_loss: 0.0278 - val_mean_squared_error: 0.0017\n",
            "Epoch 18/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0276 - mean_squared_error: 0.0023 - val_loss: 0.0266 - val_mean_squared_error: 0.0016\n",
            "Epoch 19/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0272 - mean_squared_error: 0.0022 - val_loss: 0.0316 - val_mean_squared_error: 0.0026\n",
            "Epoch 20/50\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0271 - mean_squared_error: 0.0022 - val_loss: 0.0272 - val_mean_squared_error: 0.0018\n",
            "Epoch 21/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0269 - mean_squared_error: 0.0021 - val_loss: 0.0254 - val_mean_squared_error: 0.0015\n",
            "Epoch 22/50\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0267 - mean_squared_error: 0.0021 - val_loss: 0.0265 - val_mean_squared_error: 0.0016\n",
            "Epoch 23/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0265 - mean_squared_error: 0.0021 - val_loss: 0.0260 - val_mean_squared_error: 0.0015\n",
            "Epoch 24/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0263 - mean_squared_error: 0.0020 - val_loss: 0.0267 - val_mean_squared_error: 0.0016\n",
            "Epoch 25/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0262 - mean_squared_error: 0.0020 - val_loss: 0.0261 - val_mean_squared_error: 0.0016\n",
            "Epoch 26/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0260 - mean_squared_error: 0.0020 - val_loss: 0.0256 - val_mean_squared_error: 0.0016\n",
            "Epoch 27/50\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0259 - mean_squared_error: 0.0019 - val_loss: 0.0253 - val_mean_squared_error: 0.0015\n",
            "Epoch 28/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0257 - mean_squared_error: 0.0019 - val_loss: 0.0260 - val_mean_squared_error: 0.0016\n",
            "Epoch 29/50\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0256 - mean_squared_error: 0.0019 - val_loss: 0.0250 - val_mean_squared_error: 0.0015\n",
            "Epoch 30/50\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0255 - mean_squared_error: 0.0019 - val_loss: 0.0267 - val_mean_squared_error: 0.0016\n",
            "Epoch 31/50\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0255 - mean_squared_error: 0.0019 - val_loss: 0.0261 - val_mean_squared_error: 0.0016\n",
            "Epoch 32/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0254 - mean_squared_error: 0.0018 - val_loss: 0.0259 - val_mean_squared_error: 0.0016\n",
            "Epoch 33/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0252 - mean_squared_error: 0.0018 - val_loss: 0.0255 - val_mean_squared_error: 0.0015\n",
            "Epoch 34/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0251 - mean_squared_error: 0.0018 - val_loss: 0.0256 - val_mean_squared_error: 0.0016\n",
            "Epoch 35/50\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0251 - mean_squared_error: 0.0017 - val_loss: 0.0255 - val_mean_squared_error: 0.0015\n",
            "Epoch 36/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0249 - mean_squared_error: 0.0017 - val_loss: 0.0262 - val_mean_squared_error: 0.0016\n",
            "Epoch 37/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0248 - mean_squared_error: 0.0017 - val_loss: 0.0258 - val_mean_squared_error: 0.0015\n",
            "Epoch 38/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0248 - mean_squared_error: 0.0017 - val_loss: 0.0259 - val_mean_squared_error: 0.0015\n",
            "Epoch 39/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0247 - mean_squared_error: 0.0017 - val_loss: 0.0256 - val_mean_squared_error: 0.0015\n",
            "Epoch 40/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0246 - mean_squared_error: 0.0016 - val_loss: 0.0250 - val_mean_squared_error: 0.0015\n",
            "Epoch 41/50\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0245 - mean_squared_error: 0.0016 - val_loss: 0.0251 - val_mean_squared_error: 0.0015\n",
            "Epoch 42/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0245 - mean_squared_error: 0.0016 - val_loss: 0.0261 - val_mean_squared_error: 0.0016\n",
            "Epoch 43/50\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0244 - mean_squared_error: 0.0016 - val_loss: 0.0255 - val_mean_squared_error: 0.0015\n",
            "Epoch 44/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0243 - mean_squared_error: 0.0016 - val_loss: 0.0253 - val_mean_squared_error: 0.0015\n",
            "Epoch 45/50\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0243 - mean_squared_error: 0.0016 - val_loss: 0.0257 - val_mean_squared_error: 0.0015\n",
            "Epoch 46/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0242 - mean_squared_error: 0.0016 - val_loss: 0.0252 - val_mean_squared_error: 0.0016\n",
            "Epoch 47/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0241 - mean_squared_error: 0.0016 - val_loss: 0.0263 - val_mean_squared_error: 0.0016\n",
            "Epoch 48/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0240 - mean_squared_error: 0.0016 - val_loss: 0.0260 - val_mean_squared_error: 0.0016\n",
            "Epoch 49/50\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0240 - mean_squared_error: 0.0016 - val_loss: 0.0329 - val_mean_squared_error: 0.0048\n",
            "Epoch 50/50\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0239 - mean_squared_error: 0.0016 - val_loss: 0.0253 - val_mean_squared_error: 0.0015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAjsHywG9Sgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6b4f7a7-3905-4e11-d539-a1456922f302"
      },
      "source": [
        "m, enc, dec = seq2seq(history, future, latent_dim=100, num_features=4, mn=1.0)\n",
        "m.compile(optimizer='rmsprop', loss=MAE, metrics=[MSE])\n",
        "h = m.fit(x=train_data[0], y=train_data[1], batch_size=train_batch, epochs=50, \n",
        "          validation_data=vad_data)\n",
        "plot_train_history(h, 'Seq2Seq 100 dimensions')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_model_inference\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, 4)]         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 100)         42000     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                [(None, 100), (None, 100) 80400     \n",
            "=================================================================\n",
            "Total params: 122,400\n",
            "Trainable params: 122,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"decoder_model_inference\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 100),  40800       input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 1)      101         lstm_2[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 40,901\n",
            "Trainable params: 40,901\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"seq2seq_training_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 4)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, None, 100)    42000       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 100), (None, 80400       lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 100),  40800       input_2[0][0]                    \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 1)      101         lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 163,301\n",
            "Trainable params: 163,301\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 70487 samples, validate on 9116 samples\n",
            "Epoch 1/50\n",
            "70487/70487 [==============================] - 15s 208us/sample - loss: 0.1162 - mean_squared_error: 0.0305 - val_loss: 0.0806 - val_mean_squared_error: 0.0197\n",
            "Epoch 2/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0687 - mean_squared_error: 0.0127 - val_loss: 0.0715 - val_mean_squared_error: 0.0118\n",
            "Epoch 3/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0499 - mean_squared_error: 0.0064 - val_loss: 0.0410 - val_mean_squared_error: 0.0029\n",
            "Epoch 4/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0402 - mean_squared_error: 0.0041 - val_loss: 0.0334 - val_mean_squared_error: 0.0022\n",
            "Epoch 5/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0360 - mean_squared_error: 0.0035 - val_loss: 0.0533 - val_mean_squared_error: 0.0141\n",
            "Epoch 6/50\n",
            "70487/70487 [==============================] - 8s 119us/sample - loss: 0.0340 - mean_squared_error: 0.0033 - val_loss: 0.0293 - val_mean_squared_error: 0.0018\n",
            "Epoch 7/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0325 - mean_squared_error: 0.0031 - val_loss: 0.0287 - val_mean_squared_error: 0.0018\n",
            "Epoch 8/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0313 - mean_squared_error: 0.0029 - val_loss: 0.0288 - val_mean_squared_error: 0.0018\n",
            "Epoch 9/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0304 - mean_squared_error: 0.0028 - val_loss: 0.0285 - val_mean_squared_error: 0.0017\n",
            "Epoch 10/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0297 - mean_squared_error: 0.0026 - val_loss: 0.0299 - val_mean_squared_error: 0.0020\n",
            "Epoch 11/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0292 - mean_squared_error: 0.0026 - val_loss: 0.0280 - val_mean_squared_error: 0.0018\n",
            "Epoch 12/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0287 - mean_squared_error: 0.0025 - val_loss: 0.0262 - val_mean_squared_error: 0.0016\n",
            "Epoch 13/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0282 - mean_squared_error: 0.0023 - val_loss: 0.0276 - val_mean_squared_error: 0.0017\n",
            "Epoch 14/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0279 - mean_squared_error: 0.0023 - val_loss: 0.0277 - val_mean_squared_error: 0.0018\n",
            "Epoch 15/50\n",
            "70487/70487 [==============================] - 8s 119us/sample - loss: 0.0276 - mean_squared_error: 0.0022 - val_loss: 0.0266 - val_mean_squared_error: 0.0016\n",
            "Epoch 16/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0273 - mean_squared_error: 0.0022 - val_loss: 0.0272 - val_mean_squared_error: 0.0017\n",
            "Epoch 17/50\n",
            "70487/70487 [==============================] - 8s 119us/sample - loss: 0.0271 - mean_squared_error: 0.0021 - val_loss: 0.0266 - val_mean_squared_error: 0.0016\n",
            "Epoch 18/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0269 - mean_squared_error: 0.0021 - val_loss: 0.0271 - val_mean_squared_error: 0.0016\n",
            "Epoch 19/50\n",
            "70487/70487 [==============================] - 9s 122us/sample - loss: 0.0266 - mean_squared_error: 0.0020 - val_loss: 0.0269 - val_mean_squared_error: 0.0016\n",
            "Epoch 20/50\n",
            "70487/70487 [==============================] - 8s 119us/sample - loss: 0.0264 - mean_squared_error: 0.0020 - val_loss: 0.0262 - val_mean_squared_error: 0.0016\n",
            "Epoch 21/50\n",
            "70487/70487 [==============================] - 8s 119us/sample - loss: 0.0261 - mean_squared_error: 0.0019 - val_loss: 0.0271 - val_mean_squared_error: 0.0016\n",
            "Epoch 22/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0260 - mean_squared_error: 0.0019 - val_loss: 0.0259 - val_mean_squared_error: 0.0016\n",
            "Epoch 23/50\n",
            "70487/70487 [==============================] - 9s 121us/sample - loss: 0.0258 - mean_squared_error: 0.0018 - val_loss: 0.0272 - val_mean_squared_error: 0.0017\n",
            "Epoch 24/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0256 - mean_squared_error: 0.0018 - val_loss: 0.0255 - val_mean_squared_error: 0.0016\n",
            "Epoch 25/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0254 - mean_squared_error: 0.0018 - val_loss: 0.0267 - val_mean_squared_error: 0.0016\n",
            "Epoch 26/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0253 - mean_squared_error: 0.0018 - val_loss: 0.0262 - val_mean_squared_error: 0.0016\n",
            "Epoch 27/50\n",
            "70487/70487 [==============================] - 9s 121us/sample - loss: 0.0251 - mean_squared_error: 0.0017 - val_loss: 0.0260 - val_mean_squared_error: 0.0016\n",
            "Epoch 28/50\n",
            "70487/70487 [==============================] - 9s 121us/sample - loss: 0.0249 - mean_squared_error: 0.0017 - val_loss: 0.0255 - val_mean_squared_error: 0.0016\n",
            "Epoch 29/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0247 - mean_squared_error: 0.0016 - val_loss: 0.0258 - val_mean_squared_error: 0.0016\n",
            "Epoch 30/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0245 - mean_squared_error: 0.0016 - val_loss: 0.0264 - val_mean_squared_error: 0.0017\n",
            "Epoch 31/50\n",
            "70487/70487 [==============================] - 9s 121us/sample - loss: 0.0243 - mean_squared_error: 0.0016 - val_loss: 0.0259 - val_mean_squared_error: 0.0016\n",
            "Epoch 32/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0241 - mean_squared_error: 0.0016 - val_loss: 0.0256 - val_mean_squared_error: 0.0016\n",
            "Epoch 33/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0240 - mean_squared_error: 0.0016 - val_loss: 0.0264 - val_mean_squared_error: 0.0017\n",
            "Epoch 34/50\n",
            "70487/70487 [==============================] - 8s 119us/sample - loss: 0.0238 - mean_squared_error: 0.0015 - val_loss: 0.0258 - val_mean_squared_error: 0.0016\n",
            "Epoch 35/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0236 - mean_squared_error: 0.0015 - val_loss: 0.0269 - val_mean_squared_error: 0.0017\n",
            "Epoch 36/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0234 - mean_squared_error: 0.0015 - val_loss: 0.0270 - val_mean_squared_error: 0.0018\n",
            "Epoch 37/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0233 - mean_squared_error: 0.0015 - val_loss: 0.0265 - val_mean_squared_error: 0.0017\n",
            "Epoch 38/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0231 - mean_squared_error: 0.0014 - val_loss: 0.0268 - val_mean_squared_error: 0.0017\n",
            "Epoch 39/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0229 - mean_squared_error: 0.0014 - val_loss: 0.0271 - val_mean_squared_error: 0.0017\n",
            "Epoch 40/50\n",
            "70487/70487 [==============================] - 9s 121us/sample - loss: 0.0228 - mean_squared_error: 0.0014 - val_loss: 0.0269 - val_mean_squared_error: 0.0017\n",
            "Epoch 41/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0226 - mean_squared_error: 0.0014 - val_loss: 0.0265 - val_mean_squared_error: 0.0017\n",
            "Epoch 42/50\n",
            "70487/70487 [==============================] - 9s 121us/sample - loss: 0.0224 - mean_squared_error: 0.0014 - val_loss: 0.0268 - val_mean_squared_error: 0.0017\n",
            "Epoch 43/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0222 - mean_squared_error: 0.0014 - val_loss: 0.0267 - val_mean_squared_error: 0.0017\n",
            "Epoch 44/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0220 - mean_squared_error: 0.0014 - val_loss: 0.0273 - val_mean_squared_error: 0.0018\n",
            "Epoch 45/50\n",
            "70487/70487 [==============================] - 8s 121us/sample - loss: 0.0219 - mean_squared_error: 0.0013 - val_loss: 0.0270 - val_mean_squared_error: 0.0017\n",
            "Epoch 46/50\n",
            "70487/70487 [==============================] - 9s 121us/sample - loss: 0.0217 - mean_squared_error: 0.0013 - val_loss: 0.0272 - val_mean_squared_error: 0.0017\n",
            "Epoch 47/50\n",
            "70487/70487 [==============================] - 9s 121us/sample - loss: 0.0216 - mean_squared_error: 0.0013 - val_loss: 0.0280 - val_mean_squared_error: 0.0019\n",
            "Epoch 48/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0214 - mean_squared_error: 0.0013 - val_loss: 0.0275 - val_mean_squared_error: 0.0018\n",
            "Epoch 49/50\n",
            "70487/70487 [==============================] - 8s 120us/sample - loss: 0.0213 - mean_squared_error: 0.0013 - val_loss: 0.0273 - val_mean_squared_error: 0.0018\n",
            "Epoch 50/50\n",
            "70487/70487 [==============================] - 9s 121us/sample - loss: 0.0211 - mean_squared_error: 0.0013 - val_loss: 0.0278 - val_mean_squared_error: 0.0018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCJbAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9nanSkKCrHG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2fa94744-faec-4006-b5b5-bee9d5df66b0"
      },
      "source": [
        "m, enc, dec = seq2seq(history, future, latent_dim=50, num_features=4, mn=.5)\n",
        "m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4, clipvalue=1.0), loss=MSE, metrics=[MAE, MAPE])\n",
        "h = m.fit(x=train_data[0], y=train_data[1], batch_size=train_batch, epochs=100, \n",
        "          validation_data=vad_data)\n",
        "plot_train_history(h, 'Seq2Seq 50 dimensions, Adam lr=1e-4 y mn=0.5')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_model_inference\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, 4)]         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 50)          11000     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                [(None, 50), (None, 50),  20200     \n",
            "=================================================================\n",
            "Total params: 31,200\n",
            "Trainable params: 31,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"decoder_model_inference\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 50), ( 10400       input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 1)      51          lstm_2[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"seq2seq_training_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 4)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, None, 50)     11000       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 50), (None,  20200       lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 50), ( 10400       input_2[0][0]                    \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 1)      51          lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 41,651\n",
            "Trainable params: 41,651\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 70487 samples, validate on 9116 samples\n",
            "Epoch 1/100\n",
            "70487/70487 [==============================] - 14s 193us/sample - loss: 0.1005 - mean_absolute_error: 0.2468 - mean_absolute_percentage_error: 21110052.0000 - val_loss: 0.0585 - val_mean_absolute_error: 0.1946 - val_mean_absolute_percentage_error: 25312622.0000\n",
            "Epoch 2/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0465 - mean_absolute_error: 0.1686 - mean_absolute_percentage_error: 19516624.0000 - val_loss: 0.0360 - val_mean_absolute_error: 0.1469 - val_mean_absolute_percentage_error: 15585729.0000\n",
            "Epoch 3/100\n",
            "70487/70487 [==============================] - 8s 108us/sample - loss: 0.0302 - mean_absolute_error: 0.1326 - mean_absolute_percentage_error: 12926915.0000 - val_loss: 0.0251 - val_mean_absolute_error: 0.1204 - val_mean_absolute_percentage_error: 11590872.0000\n",
            "Epoch 4/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0220 - mean_absolute_error: 0.1117 - mean_absolute_percentage_error: 10261259.0000 - val_loss: 0.0192 - val_mean_absolute_error: 0.1044 - val_mean_absolute_percentage_error: 9368666.0000\n",
            "Epoch 5/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0176 - mean_absolute_error: 0.0990 - mean_absolute_percentage_error: 9025285.0000 - val_loss: 0.0157 - val_mean_absolute_error: 0.0938 - val_mean_absolute_percentage_error: 8644604.0000\n",
            "Epoch 6/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0149 - mean_absolute_error: 0.0903 - mean_absolute_percentage_error: 8216274.5000 - val_loss: 0.0135 - val_mean_absolute_error: 0.0873 - val_mean_absolute_percentage_error: 7491508.5000\n",
            "Epoch 7/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0130 - mean_absolute_error: 0.0839 - mean_absolute_percentage_error: 7614156.0000 - val_loss: 0.0118 - val_mean_absolute_error: 0.0813 - val_mean_absolute_percentage_error: 7542118.5000\n",
            "Epoch 8/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0115 - mean_absolute_error: 0.0786 - mean_absolute_percentage_error: 7004998.0000 - val_loss: 0.0104 - val_mean_absolute_error: 0.0757 - val_mean_absolute_percentage_error: 6534575.0000\n",
            "Epoch 9/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0103 - mean_absolute_error: 0.0741 - mean_absolute_percentage_error: 6375546.5000 - val_loss: 0.0094 - val_mean_absolute_error: 0.0717 - val_mean_absolute_percentage_error: 5816542.5000\n",
            "Epoch 10/100\n",
            "70487/70487 [==============================] - 8s 108us/sample - loss: 0.0094 - mean_absolute_error: 0.0702 - mean_absolute_percentage_error: 5737349.5000 - val_loss: 0.0084 - val_mean_absolute_error: 0.0680 - val_mean_absolute_percentage_error: 5559230.0000\n",
            "Epoch 11/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0085 - mean_absolute_error: 0.0667 - mean_absolute_percentage_error: 5129920.0000 - val_loss: 0.0076 - val_mean_absolute_error: 0.0644 - val_mean_absolute_percentage_error: 4619478.0000\n",
            "Epoch 12/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0078 - mean_absolute_error: 0.0635 - mean_absolute_percentage_error: 4568829.5000 - val_loss: 0.0069 - val_mean_absolute_error: 0.0614 - val_mean_absolute_percentage_error: 4300146.5000\n",
            "Epoch 13/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0071 - mean_absolute_error: 0.0607 - mean_absolute_percentage_error: 4069641.5000 - val_loss: 0.0064 - val_mean_absolute_error: 0.0586 - val_mean_absolute_percentage_error: 3585307.7500\n",
            "Epoch 14/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0066 - mean_absolute_error: 0.0581 - mean_absolute_percentage_error: 3626656.7500 - val_loss: 0.0059 - val_mean_absolute_error: 0.0563 - val_mean_absolute_percentage_error: 3364456.7500\n",
            "Epoch 15/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0061 - mean_absolute_error: 0.0558 - mean_absolute_percentage_error: 3220674.5000 - val_loss: 0.0055 - val_mean_absolute_error: 0.0545 - val_mean_absolute_percentage_error: 2948751.7500\n",
            "Epoch 16/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0058 - mean_absolute_error: 0.0540 - mean_absolute_percentage_error: 2919516.5000 - val_loss: 0.0052 - val_mean_absolute_error: 0.0528 - val_mean_absolute_percentage_error: 3194817.0000\n",
            "Epoch 17/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0055 - mean_absolute_error: 0.0524 - mean_absolute_percentage_error: 2659884.0000 - val_loss: 0.0049 - val_mean_absolute_error: 0.0510 - val_mean_absolute_percentage_error: 2667388.2500\n",
            "Epoch 18/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0052 - mean_absolute_error: 0.0509 - mean_absolute_percentage_error: 2439470.2500 - val_loss: 0.0046 - val_mean_absolute_error: 0.0496 - val_mean_absolute_percentage_error: 2405078.2500\n",
            "Epoch 19/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0050 - mean_absolute_error: 0.0496 - mean_absolute_percentage_error: 2265497.2500 - val_loss: 0.0044 - val_mean_absolute_error: 0.0484 - val_mean_absolute_percentage_error: 1937389.5000\n",
            "Epoch 20/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0047 - mean_absolute_error: 0.0484 - mean_absolute_percentage_error: 2088263.3750 - val_loss: 0.0042 - val_mean_absolute_error: 0.0473 - val_mean_absolute_percentage_error: 1877980.0000\n",
            "Epoch 21/100\n",
            "70487/70487 [==============================] - 8s 106us/sample - loss: 0.0046 - mean_absolute_error: 0.0473 - mean_absolute_percentage_error: 1959477.7500 - val_loss: 0.0040 - val_mean_absolute_error: 0.0461 - val_mean_absolute_percentage_error: 1730467.1250\n",
            "Epoch 22/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0044 - mean_absolute_error: 0.0463 - mean_absolute_percentage_error: 1822269.7500 - val_loss: 0.0039 - val_mean_absolute_error: 0.0453 - val_mean_absolute_percentage_error: 1557131.0000\n",
            "Epoch 23/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0042 - mean_absolute_error: 0.0454 - mean_absolute_percentage_error: 1699351.0000 - val_loss: 0.0038 - val_mean_absolute_error: 0.0443 - val_mean_absolute_percentage_error: 1482003.8750\n",
            "Epoch 24/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0041 - mean_absolute_error: 0.0446 - mean_absolute_percentage_error: 1583313.5000 - val_loss: 0.0036 - val_mean_absolute_error: 0.0437 - val_mean_absolute_percentage_error: 1384193.8750\n",
            "Epoch 25/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0040 - mean_absolute_error: 0.0439 - mean_absolute_percentage_error: 1493310.1250 - val_loss: 0.0035 - val_mean_absolute_error: 0.0429 - val_mean_absolute_percentage_error: 1300179.5000\n",
            "Epoch 26/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0039 - mean_absolute_error: 0.0433 - mean_absolute_percentage_error: 1405643.7500 - val_loss: 0.0035 - val_mean_absolute_error: 0.0425 - val_mean_absolute_percentage_error: 1169195.7500\n",
            "Epoch 27/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0038 - mean_absolute_error: 0.0428 - mean_absolute_percentage_error: 1332803.6250 - val_loss: 0.0035 - val_mean_absolute_error: 0.0430 - val_mean_absolute_percentage_error: 1622177.8750\n",
            "Epoch 28/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0038 - mean_absolute_error: 0.0424 - mean_absolute_percentage_error: 1264662.0000 - val_loss: 0.0034 - val_mean_absolute_error: 0.0415 - val_mean_absolute_percentage_error: 1144993.5000\n",
            "Epoch 29/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0037 - mean_absolute_error: 0.0421 - mean_absolute_percentage_error: 1217847.8750 - val_loss: 0.0033 - val_mean_absolute_error: 0.0415 - val_mean_absolute_percentage_error: 1179325.3750\n",
            "Epoch 30/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0037 - mean_absolute_error: 0.0417 - mean_absolute_percentage_error: 1161984.8750 - val_loss: 0.0033 - val_mean_absolute_error: 0.0414 - val_mean_absolute_percentage_error: 1135714.8750\n",
            "Epoch 31/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0036 - mean_absolute_error: 0.0415 - mean_absolute_percentage_error: 1116114.8750 - val_loss: 0.0032 - val_mean_absolute_error: 0.0410 - val_mean_absolute_percentage_error: 1079323.3750\n",
            "Epoch 32/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0036 - mean_absolute_error: 0.0412 - mean_absolute_percentage_error: 1070763.8750 - val_loss: 0.0032 - val_mean_absolute_error: 0.0407 - val_mean_absolute_percentage_error: 932492.8125\n",
            "Epoch 33/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0036 - mean_absolute_error: 0.0409 - mean_absolute_percentage_error: 1032244.7500 - val_loss: 0.0032 - val_mean_absolute_error: 0.0408 - val_mean_absolute_percentage_error: 1241548.0000\n",
            "Epoch 34/100\n",
            "70487/70487 [==============================] - 8s 106us/sample - loss: 0.0035 - mean_absolute_error: 0.0407 - mean_absolute_percentage_error: 1007154.5000 - val_loss: 0.0032 - val_mean_absolute_error: 0.0403 - val_mean_absolute_percentage_error: 872076.5000\n",
            "Epoch 35/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0035 - mean_absolute_error: 0.0405 - mean_absolute_percentage_error: 962649.8750 - val_loss: 0.0031 - val_mean_absolute_error: 0.0400 - val_mean_absolute_percentage_error: 964832.8125\n",
            "Epoch 36/100\n",
            "70487/70487 [==============================] - 8s 106us/sample - loss: 0.0035 - mean_absolute_error: 0.0403 - mean_absolute_percentage_error: 931236.3125 - val_loss: 0.0031 - val_mean_absolute_error: 0.0403 - val_mean_absolute_percentage_error: 1091252.3750\n",
            "Epoch 37/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0035 - mean_absolute_error: 0.0401 - mean_absolute_percentage_error: 902960.6250 - val_loss: 0.0031 - val_mean_absolute_error: 0.0396 - val_mean_absolute_percentage_error: 804783.1875\n",
            "Epoch 38/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0034 - mean_absolute_error: 0.0399 - mean_absolute_percentage_error: 873768.5625 - val_loss: 0.0030 - val_mean_absolute_error: 0.0393 - val_mean_absolute_percentage_error: 827468.6875\n",
            "Epoch 39/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0034 - mean_absolute_error: 0.0397 - mean_absolute_percentage_error: 845819.1875 - val_loss: 0.0031 - val_mean_absolute_error: 0.0395 - val_mean_absolute_percentage_error: 706203.6250\n",
            "Epoch 40/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0034 - mean_absolute_error: 0.0396 - mean_absolute_percentage_error: 813490.5625 - val_loss: 0.0030 - val_mean_absolute_error: 0.0390 - val_mean_absolute_percentage_error: 709007.4375\n",
            "Epoch 41/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0034 - mean_absolute_error: 0.0394 - mean_absolute_percentage_error: 784918.6250 - val_loss: 0.0030 - val_mean_absolute_error: 0.0389 - val_mean_absolute_percentage_error: 709900.3750\n",
            "Epoch 42/100\n",
            "70487/70487 [==============================] - 8s 106us/sample - loss: 0.0034 - mean_absolute_error: 0.0393 - mean_absolute_percentage_error: 768414.4375 - val_loss: 0.0030 - val_mean_absolute_error: 0.0392 - val_mean_absolute_percentage_error: 819619.0625\n",
            "Epoch 43/100\n",
            "70487/70487 [==============================] - 8s 108us/sample - loss: 0.0033 - mean_absolute_error: 0.0392 - mean_absolute_percentage_error: 747817.0000 - val_loss: 0.0030 - val_mean_absolute_error: 0.0386 - val_mean_absolute_percentage_error: 680741.0625\n",
            "Epoch 44/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0033 - mean_absolute_error: 0.0390 - mean_absolute_percentage_error: 721497.5625 - val_loss: 0.0029 - val_mean_absolute_error: 0.0384 - val_mean_absolute_percentage_error: 664133.1875\n",
            "Epoch 45/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0033 - mean_absolute_error: 0.0389 - mean_absolute_percentage_error: 700832.0000 - val_loss: 0.0029 - val_mean_absolute_error: 0.0383 - val_mean_absolute_percentage_error: 666495.1250\n",
            "Epoch 46/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0033 - mean_absolute_error: 0.0388 - mean_absolute_percentage_error: 690604.7500 - val_loss: 0.0029 - val_mean_absolute_error: 0.0384 - val_mean_absolute_percentage_error: 694835.5000\n",
            "Epoch 47/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0033 - mean_absolute_error: 0.0386 - mean_absolute_percentage_error: 673386.6875 - val_loss: 0.0029 - val_mean_absolute_error: 0.0380 - val_mean_absolute_percentage_error: 596169.5625\n",
            "Epoch 48/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0032 - mean_absolute_error: 0.0385 - mean_absolute_percentage_error: 670024.3125 - val_loss: 0.0029 - val_mean_absolute_error: 0.0379 - val_mean_absolute_percentage_error: 590880.6875\n",
            "Epoch 49/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0032 - mean_absolute_error: 0.0384 - mean_absolute_percentage_error: 653492.6875 - val_loss: 0.0029 - val_mean_absolute_error: 0.0379 - val_mean_absolute_percentage_error: 549758.3125\n",
            "Epoch 50/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0032 - mean_absolute_error: 0.0383 - mean_absolute_percentage_error: 641901.3750 - val_loss: 0.0028 - val_mean_absolute_error: 0.0377 - val_mean_absolute_percentage_error: 629729.3125\n",
            "Epoch 51/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0032 - mean_absolute_error: 0.0382 - mean_absolute_percentage_error: 636897.6875 - val_loss: 0.0028 - val_mean_absolute_error: 0.0378 - val_mean_absolute_percentage_error: 786723.5000\n",
            "Epoch 52/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0032 - mean_absolute_error: 0.0382 - mean_absolute_percentage_error: 644055.2500 - val_loss: 0.0028 - val_mean_absolute_error: 0.0374 - val_mean_absolute_percentage_error: 576308.1250\n",
            "Epoch 53/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0032 - mean_absolute_error: 0.0379 - mean_absolute_percentage_error: 626964.6250 - val_loss: 0.0028 - val_mean_absolute_error: 0.0375 - val_mean_absolute_percentage_error: 524052.5625\n",
            "Epoch 54/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0031 - mean_absolute_error: 0.0379 - mean_absolute_percentage_error: 624421.8750 - val_loss: 0.0028 - val_mean_absolute_error: 0.0375 - val_mean_absolute_percentage_error: 677188.9375\n",
            "Epoch 55/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0031 - mean_absolute_error: 0.0377 - mean_absolute_percentage_error: 618519.8750 - val_loss: 0.0028 - val_mean_absolute_error: 0.0371 - val_mean_absolute_percentage_error: 562411.0000\n",
            "Epoch 56/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0031 - mean_absolute_error: 0.0376 - mean_absolute_percentage_error: 622632.3750 - val_loss: 0.0028 - val_mean_absolute_error: 0.0371 - val_mean_absolute_percentage_error: 649744.0000\n",
            "Epoch 57/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0031 - mean_absolute_error: 0.0375 - mean_absolute_percentage_error: 616733.3125 - val_loss: 0.0027 - val_mean_absolute_error: 0.0369 - val_mean_absolute_percentage_error: 549644.3125\n",
            "Epoch 58/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0031 - mean_absolute_error: 0.0374 - mean_absolute_percentage_error: 622669.3750 - val_loss: 0.0027 - val_mean_absolute_error: 0.0370 - val_mean_absolute_percentage_error: 659673.0625\n",
            "Epoch 59/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0031 - mean_absolute_error: 0.0373 - mean_absolute_percentage_error: 619082.5625 - val_loss: 0.0027 - val_mean_absolute_error: 0.0366 - val_mean_absolute_percentage_error: 539369.4375\n",
            "Epoch 60/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0030 - mean_absolute_error: 0.0372 - mean_absolute_percentage_error: 618150.6250 - val_loss: 0.0027 - val_mean_absolute_error: 0.0370 - val_mean_absolute_percentage_error: 562023.2500\n",
            "Epoch 61/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0030 - mean_absolute_error: 0.0370 - mean_absolute_percentage_error: 616663.9375 - val_loss: 0.0027 - val_mean_absolute_error: 0.0365 - val_mean_absolute_percentage_error: 598230.6875\n",
            "Epoch 62/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0030 - mean_absolute_error: 0.0369 - mean_absolute_percentage_error: 623357.0000 - val_loss: 0.0026 - val_mean_absolute_error: 0.0364 - val_mean_absolute_percentage_error: 581367.5000\n",
            "Epoch 63/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0030 - mean_absolute_error: 0.0367 - mean_absolute_percentage_error: 623381.0000 - val_loss: 0.0026 - val_mean_absolute_error: 0.0363 - val_mean_absolute_percentage_error: 757917.0000\n",
            "Epoch 64/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0030 - mean_absolute_error: 0.0365 - mean_absolute_percentage_error: 619686.1250 - val_loss: 0.0026 - val_mean_absolute_error: 0.0361 - val_mean_absolute_percentage_error: 598953.4375\n",
            "Epoch 65/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0029 - mean_absolute_error: 0.0365 - mean_absolute_percentage_error: 626146.7500 - val_loss: 0.0026 - val_mean_absolute_error: 0.0359 - val_mean_absolute_percentage_error: 576012.0000\n",
            "Epoch 66/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0029 - mean_absolute_error: 0.0363 - mean_absolute_percentage_error: 620937.4375 - val_loss: 0.0026 - val_mean_absolute_error: 0.0358 - val_mean_absolute_percentage_error: 533141.1875\n",
            "Epoch 67/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0029 - mean_absolute_error: 0.0362 - mean_absolute_percentage_error: 615147.3125 - val_loss: 0.0026 - val_mean_absolute_error: 0.0359 - val_mean_absolute_percentage_error: 754231.6875\n",
            "Epoch 68/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0029 - mean_absolute_error: 0.0361 - mean_absolute_percentage_error: 617898.5625 - val_loss: 0.0025 - val_mean_absolute_error: 0.0354 - val_mean_absolute_percentage_error: 552940.7500\n",
            "Epoch 69/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0029 - mean_absolute_error: 0.0360 - mean_absolute_percentage_error: 612743.6875 - val_loss: 0.0025 - val_mean_absolute_error: 0.0357 - val_mean_absolute_percentage_error: 635732.2500\n",
            "Epoch 70/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0029 - mean_absolute_error: 0.0359 - mean_absolute_percentage_error: 615364.2500 - val_loss: 0.0025 - val_mean_absolute_error: 0.0358 - val_mean_absolute_percentage_error: 687121.1875\n",
            "Epoch 71/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0028 - mean_absolute_error: 0.0358 - mean_absolute_percentage_error: 614361.0625 - val_loss: 0.0025 - val_mean_absolute_error: 0.0355 - val_mean_absolute_percentage_error: 620842.1250\n",
            "Epoch 72/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0028 - mean_absolute_error: 0.0357 - mean_absolute_percentage_error: 613913.7500 - val_loss: 0.0025 - val_mean_absolute_error: 0.0355 - val_mean_absolute_percentage_error: 634635.3750\n",
            "Epoch 73/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0028 - mean_absolute_error: 0.0356 - mean_absolute_percentage_error: 607018.5625 - val_loss: 0.0025 - val_mean_absolute_error: 0.0353 - val_mean_absolute_percentage_error: 607358.3750\n",
            "Epoch 74/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0028 - mean_absolute_error: 0.0356 - mean_absolute_percentage_error: 620739.4375 - val_loss: 0.0025 - val_mean_absolute_error: 0.0352 - val_mean_absolute_percentage_error: 623500.4375\n",
            "Epoch 75/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0028 - mean_absolute_error: 0.0355 - mean_absolute_percentage_error: 610519.4375 - val_loss: 0.0025 - val_mean_absolute_error: 0.0352 - val_mean_absolute_percentage_error: 595796.8125\n",
            "Epoch 76/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0028 - mean_absolute_error: 0.0354 - mean_absolute_percentage_error: 618903.0625 - val_loss: 0.0025 - val_mean_absolute_error: 0.0351 - val_mean_absolute_percentage_error: 666179.1875\n",
            "Epoch 77/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0028 - mean_absolute_error: 0.0353 - mean_absolute_percentage_error: 615771.2500 - val_loss: 0.0025 - val_mean_absolute_error: 0.0350 - val_mean_absolute_percentage_error: 630927.5000\n",
            "Epoch 78/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0028 - mean_absolute_error: 0.0353 - mean_absolute_percentage_error: 619174.0000 - val_loss: 0.0024 - val_mean_absolute_error: 0.0347 - val_mean_absolute_percentage_error: 571421.5625\n",
            "Epoch 79/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0028 - mean_absolute_error: 0.0352 - mean_absolute_percentage_error: 611815.6875 - val_loss: 0.0024 - val_mean_absolute_error: 0.0348 - val_mean_absolute_percentage_error: 599682.3125\n",
            "Epoch 80/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0351 - mean_absolute_percentage_error: 618291.4375 - val_loss: 0.0024 - val_mean_absolute_error: 0.0347 - val_mean_absolute_percentage_error: 667528.5000\n",
            "Epoch 81/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0350 - mean_absolute_percentage_error: 615759.1875 - val_loss: 0.0024 - val_mean_absolute_error: 0.0349 - val_mean_absolute_percentage_error: 592573.5000\n",
            "Epoch 82/100\n",
            "70487/70487 [==============================] - 8s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0350 - mean_absolute_percentage_error: 621348.5000 - val_loss: 0.0024 - val_mean_absolute_error: 0.0348 - val_mean_absolute_percentage_error: 680785.8750\n",
            "Epoch 83/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0350 - mean_absolute_percentage_error: 626168.9375 - val_loss: 0.0024 - val_mean_absolute_error: 0.0344 - val_mean_absolute_percentage_error: 617615.8750\n",
            "Epoch 84/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0027 - mean_absolute_error: 0.0348 - mean_absolute_percentage_error: 619023.0000 - val_loss: 0.0024 - val_mean_absolute_error: 0.0345 - val_mean_absolute_percentage_error: 590402.5625\n",
            "Epoch 85/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0348 - mean_absolute_percentage_error: 614197.2500 - val_loss: 0.0024 - val_mean_absolute_error: 0.0346 - val_mean_absolute_percentage_error: 568107.8125\n",
            "Epoch 86/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0348 - mean_absolute_percentage_error: 615084.8750 - val_loss: 0.0024 - val_mean_absolute_error: 0.0344 - val_mean_absolute_percentage_error: 588670.7500\n",
            "Epoch 87/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0347 - mean_absolute_percentage_error: 610619.5625 - val_loss: 0.0024 - val_mean_absolute_error: 0.0344 - val_mean_absolute_percentage_error: 637533.9375\n",
            "Epoch 88/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0027 - mean_absolute_error: 0.0347 - mean_absolute_percentage_error: 611307.5625 - val_loss: 0.0024 - val_mean_absolute_error: 0.0342 - val_mean_absolute_percentage_error: 592312.0000\n",
            "Epoch 89/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0027 - mean_absolute_error: 0.0346 - mean_absolute_percentage_error: 602748.9375 - val_loss: 0.0024 - val_mean_absolute_error: 0.0343 - val_mean_absolute_percentage_error: 591618.9375\n",
            "Epoch 90/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0027 - mean_absolute_error: 0.0346 - mean_absolute_percentage_error: 602453.3125 - val_loss: 0.0024 - val_mean_absolute_error: 0.0343 - val_mean_absolute_percentage_error: 593550.8125\n",
            "Epoch 91/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0346 - mean_absolute_percentage_error: 599963.3750 - val_loss: 0.0024 - val_mean_absolute_error: 0.0347 - val_mean_absolute_percentage_error: 570070.0625\n",
            "Epoch 92/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0345 - mean_absolute_percentage_error: 595714.0000 - val_loss: 0.0024 - val_mean_absolute_error: 0.0342 - val_mean_absolute_percentage_error: 626259.5000\n",
            "Epoch 93/100\n",
            "70487/70487 [==============================] - 8s 108us/sample - loss: 0.0027 - mean_absolute_error: 0.0345 - mean_absolute_percentage_error: 598809.5625 - val_loss: 0.0024 - val_mean_absolute_error: 0.0342 - val_mean_absolute_percentage_error: 620289.1250\n",
            "Epoch 94/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0345 - mean_absolute_percentage_error: 591814.5000 - val_loss: 0.0024 - val_mean_absolute_error: 0.0343 - val_mean_absolute_percentage_error: 551667.1875\n",
            "Epoch 95/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0027 - mean_absolute_error: 0.0344 - mean_absolute_percentage_error: 584543.0625 - val_loss: 0.0023 - val_mean_absolute_error: 0.0344 - val_mean_absolute_percentage_error: 621866.3125\n",
            "Epoch 96/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0344 - mean_absolute_percentage_error: 580581.3750 - val_loss: 0.0023 - val_mean_absolute_error: 0.0343 - val_mean_absolute_percentage_error: 613591.8750\n",
            "Epoch 97/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0026 - mean_absolute_error: 0.0344 - mean_absolute_percentage_error: 578122.0625 - val_loss: 0.0023 - val_mean_absolute_error: 0.0339 - val_mean_absolute_percentage_error: 547833.1250\n",
            "Epoch 98/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0027 - mean_absolute_error: 0.0344 - mean_absolute_percentage_error: 578427.8750 - val_loss: 0.0023 - val_mean_absolute_error: 0.0340 - val_mean_absolute_percentage_error: 538930.6875\n",
            "Epoch 99/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0026 - mean_absolute_error: 0.0343 - mean_absolute_percentage_error: 573299.6875 - val_loss: 0.0023 - val_mean_absolute_error: 0.0340 - val_mean_absolute_percentage_error: 559120.5625\n",
            "Epoch 100/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0026 - mean_absolute_error: 0.0343 - mean_absolute_percentage_error: 565677.4375 - val_loss: 0.0023 - val_mean_absolute_error: 0.0339 - val_mean_absolute_percentage_error: 525618.8750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4UxEvCzIiKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e042ff78-4ced-4c74-b8c1-958e955e7b5f"
      },
      "source": [
        "m, enc, dec = seq2seq(history, future, latent_dim=50, num_features=4, mn=.5)\n",
        "m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4, clipvalue=1.0), loss=MSE, metrics=[MAE, MAPE])\n",
        "h = m.fit(x=train_data[0], y=train_data[1], batch_size=train_batch, epochs=100, \n",
        "          validation_data=vad_data)\n",
        "plot_train_history(h, 'Seq2Seq 50 dimensions, Adam lr=5e-4 y mn=0.5')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_model_inference\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, 4)]         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 50)          11000     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                [(None, 50), (None, 50),  20200     \n",
            "=================================================================\n",
            "Total params: 31,200\n",
            "Trainable params: 31,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"decoder_model_inference\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 50), ( 10400       input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 1)      51          lstm_2[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"seq2seq_training_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 4)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, None, 50)     11000       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 50), (None,  20200       lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 50), ( 10400       input_2[0][0]                    \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 1)      51          lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 41,651\n",
            "Trainable params: 41,651\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 70487 samples, validate on 9116 samples\n",
            "Epoch 1/100\n",
            "70487/70487 [==============================] - 14s 195us/sample - loss: 0.0589 - mean_absolute_error: 0.1823 - mean_absolute_percentage_error: 18342296.0000 - val_loss: 0.0230 - val_mean_absolute_error: 0.1156 - val_mean_absolute_percentage_error: 11654381.0000\n",
            "Epoch 2/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0163 - mean_absolute_error: 0.0945 - mean_absolute_percentage_error: 9723277.0000 - val_loss: 0.0119 - val_mean_absolute_error: 0.0817 - val_mean_absolute_percentage_error: 9522491.0000\n",
            "Epoch 3/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0104 - mean_absolute_error: 0.0742 - mean_absolute_percentage_error: 7293944.0000 - val_loss: 0.0083 - val_mean_absolute_error: 0.0674 - val_mean_absolute_percentage_error: 5649192.5000\n",
            "Epoch 4/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0079 - mean_absolute_error: 0.0641 - mean_absolute_percentage_error: 5358637.5000 - val_loss: 0.0066 - val_mean_absolute_error: 0.0604 - val_mean_absolute_percentage_error: 4252093.0000\n",
            "Epoch 5/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0064 - mean_absolute_error: 0.0575 - mean_absolute_percentage_error: 3939751.7500 - val_loss: 0.0053 - val_mean_absolute_error: 0.0538 - val_mean_absolute_percentage_error: 3396436.2500\n",
            "Epoch 6/100\n",
            "70487/70487 [==============================] - 8s 106us/sample - loss: 0.0055 - mean_absolute_error: 0.0529 - mean_absolute_percentage_error: 3081181.0000 - val_loss: 0.0047 - val_mean_absolute_error: 0.0504 - val_mean_absolute_percentage_error: 2530736.2500\n",
            "Epoch 7/100\n",
            "70487/70487 [==============================] - 8s 106us/sample - loss: 0.0050 - mean_absolute_error: 0.0502 - mean_absolute_percentage_error: 2547567.0000 - val_loss: 0.0044 - val_mean_absolute_error: 0.0489 - val_mean_absolute_percentage_error: 2827224.2500\n",
            "Epoch 8/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0047 - mean_absolute_error: 0.0480 - mean_absolute_percentage_error: 2143262.7500 - val_loss: 0.0041 - val_mean_absolute_error: 0.0468 - val_mean_absolute_percentage_error: 1901338.7500\n",
            "Epoch 9/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0044 - mean_absolute_error: 0.0465 - mean_absolute_percentage_error: 1878543.6250 - val_loss: 0.0039 - val_mean_absolute_error: 0.0454 - val_mean_absolute_percentage_error: 1918870.5000\n",
            "Epoch 10/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0042 - mean_absolute_error: 0.0452 - mean_absolute_percentage_error: 1687206.3750 - val_loss: 0.0037 - val_mean_absolute_error: 0.0440 - val_mean_absolute_percentage_error: 1414506.1250\n",
            "Epoch 11/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0040 - mean_absolute_error: 0.0443 - mean_absolute_percentage_error: 1557882.1250 - val_loss: 0.0036 - val_mean_absolute_error: 0.0436 - val_mean_absolute_percentage_error: 1726735.7500\n",
            "Epoch 12/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0039 - mean_absolute_error: 0.0433 - mean_absolute_percentage_error: 1468231.1250 - val_loss: 0.0034 - val_mean_absolute_error: 0.0421 - val_mean_absolute_percentage_error: 1281113.8750\n",
            "Epoch 13/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0037 - mean_absolute_error: 0.0423 - mean_absolute_percentage_error: 1375672.8750 - val_loss: 0.0033 - val_mean_absolute_error: 0.0410 - val_mean_absolute_percentage_error: 1109631.7500\n",
            "Epoch 14/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0036 - mean_absolute_error: 0.0414 - mean_absolute_percentage_error: 1276674.8750 - val_loss: 0.0032 - val_mean_absolute_error: 0.0405 - val_mean_absolute_percentage_error: 1036215.6875\n",
            "Epoch 15/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0035 - mean_absolute_error: 0.0407 - mean_absolute_percentage_error: 1194510.6250 - val_loss: 0.0031 - val_mean_absolute_error: 0.0401 - val_mean_absolute_percentage_error: 1034584.8750\n",
            "Epoch 16/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0034 - mean_absolute_error: 0.0401 - mean_absolute_percentage_error: 1161832.5000 - val_loss: 0.0030 - val_mean_absolute_error: 0.0390 - val_mean_absolute_percentage_error: 992954.4375\n",
            "Epoch 17/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0033 - mean_absolute_error: 0.0395 - mean_absolute_percentage_error: 1113189.1250 - val_loss: 0.0029 - val_mean_absolute_error: 0.0384 - val_mean_absolute_percentage_error: 1054530.6250\n",
            "Epoch 18/100\n",
            "70487/70487 [==============================] - 8s 108us/sample - loss: 0.0032 - mean_absolute_error: 0.0388 - mean_absolute_percentage_error: 1094083.0000 - val_loss: 0.0028 - val_mean_absolute_error: 0.0383 - val_mean_absolute_percentage_error: 1066479.0000\n",
            "Epoch 19/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0032 - mean_absolute_error: 0.0384 - mean_absolute_percentage_error: 1075736.5000 - val_loss: 0.0028 - val_mean_absolute_error: 0.0376 - val_mean_absolute_percentage_error: 953639.1250\n",
            "Epoch 20/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0031 - mean_absolute_error: 0.0378 - mean_absolute_percentage_error: 1015928.8750 - val_loss: 0.0027 - val_mean_absolute_error: 0.0374 - val_mean_absolute_percentage_error: 1151719.6250\n",
            "Epoch 21/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0030 - mean_absolute_error: 0.0373 - mean_absolute_percentage_error: 981764.5000 - val_loss: 0.0027 - val_mean_absolute_error: 0.0379 - val_mean_absolute_percentage_error: 1079912.6250\n",
            "Epoch 22/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0029 - mean_absolute_error: 0.0368 - mean_absolute_percentage_error: 919061.0000 - val_loss: 0.0026 - val_mean_absolute_error: 0.0361 - val_mean_absolute_percentage_error: 843207.4375\n",
            "Epoch 23/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0029 - mean_absolute_error: 0.0367 - mean_absolute_percentage_error: 880587.5625 - val_loss: 0.0026 - val_mean_absolute_error: 0.0362 - val_mean_absolute_percentage_error: 938950.8750\n",
            "Epoch 24/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0029 - mean_absolute_error: 0.0364 - mean_absolute_percentage_error: 831092.1250 - val_loss: 0.0025 - val_mean_absolute_error: 0.0359 - val_mean_absolute_percentage_error: 1165646.2500\n",
            "Epoch 25/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0028 - mean_absolute_error: 0.0360 - mean_absolute_percentage_error: 783338.3125 - val_loss: 0.0025 - val_mean_absolute_error: 0.0354 - val_mean_absolute_percentage_error: 645357.9375\n",
            "Epoch 26/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0028 - mean_absolute_error: 0.0359 - mean_absolute_percentage_error: 732036.5000 - val_loss: 0.0025 - val_mean_absolute_error: 0.0350 - val_mean_absolute_percentage_error: 595473.5000\n",
            "Epoch 27/100\n",
            "70487/70487 [==============================] - 8s 108us/sample - loss: 0.0028 - mean_absolute_error: 0.0357 - mean_absolute_percentage_error: 674383.9375 - val_loss: 0.0025 - val_mean_absolute_error: 0.0351 - val_mean_absolute_percentage_error: 519059.9688\n",
            "Epoch 28/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0028 - mean_absolute_error: 0.0355 - mean_absolute_percentage_error: 634261.0000 - val_loss: 0.0025 - val_mean_absolute_error: 0.0353 - val_mean_absolute_percentage_error: 564672.7500\n",
            "Epoch 29/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0028 - mean_absolute_error: 0.0355 - mean_absolute_percentage_error: 576962.0625 - val_loss: 0.0025 - val_mean_absolute_error: 0.0353 - val_mean_absolute_percentage_error: 461442.5938\n",
            "Epoch 30/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0028 - mean_absolute_error: 0.0353 - mean_absolute_percentage_error: 541767.3750 - val_loss: 0.0024 - val_mean_absolute_error: 0.0349 - val_mean_absolute_percentage_error: 528971.8750\n",
            "Epoch 31/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0028 - mean_absolute_error: 0.0353 - mean_absolute_percentage_error: 534278.0625 - val_loss: 0.0024 - val_mean_absolute_error: 0.0348 - val_mean_absolute_percentage_error: 368413.6250\n",
            "Epoch 32/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0027 - mean_absolute_error: 0.0351 - mean_absolute_percentage_error: 478096.2188 - val_loss: 0.0024 - val_mean_absolute_error: 0.0343 - val_mean_absolute_percentage_error: 425060.5312\n",
            "Epoch 33/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0350 - mean_absolute_percentage_error: 462292.3438 - val_loss: 0.0024 - val_mean_absolute_error: 0.0348 - val_mean_absolute_percentage_error: 478063.7812\n",
            "Epoch 34/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0349 - mean_absolute_percentage_error: 446127.5625 - val_loss: 0.0024 - val_mean_absolute_error: 0.0345 - val_mean_absolute_percentage_error: 416759.8438\n",
            "Epoch 35/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0349 - mean_absolute_percentage_error: 446708.0625 - val_loss: 0.0024 - val_mean_absolute_error: 0.0345 - val_mean_absolute_percentage_error: 574925.7500\n",
            "Epoch 36/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0347 - mean_absolute_percentage_error: 430006.8125 - val_loss: 0.0024 - val_mean_absolute_error: 0.0344 - val_mean_absolute_percentage_error: 461244.2188\n",
            "Epoch 37/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0346 - mean_absolute_percentage_error: 431778.0938 - val_loss: 0.0024 - val_mean_absolute_error: 0.0346 - val_mean_absolute_percentage_error: 506464.3750\n",
            "Epoch 38/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0027 - mean_absolute_error: 0.0345 - mean_absolute_percentage_error: 421066.5312 - val_loss: 0.0024 - val_mean_absolute_error: 0.0343 - val_mean_absolute_percentage_error: 423602.5312\n",
            "Epoch 39/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0027 - mean_absolute_error: 0.0344 - mean_absolute_percentage_error: 426707.5625 - val_loss: 0.0024 - val_mean_absolute_error: 0.0349 - val_mean_absolute_percentage_error: 376362.6562\n",
            "Epoch 40/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0026 - mean_absolute_error: 0.0343 - mean_absolute_percentage_error: 428321.0312 - val_loss: 0.0023 - val_mean_absolute_error: 0.0338 - val_mean_absolute_percentage_error: 390065.6250\n",
            "Epoch 41/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0026 - mean_absolute_error: 0.0343 - mean_absolute_percentage_error: 424532.5938 - val_loss: 0.0024 - val_mean_absolute_error: 0.0339 - val_mean_absolute_percentage_error: 385382.4688\n",
            "Epoch 42/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0026 - mean_absolute_error: 0.0341 - mean_absolute_percentage_error: 430324.2188 - val_loss: 0.0023 - val_mean_absolute_error: 0.0339 - val_mean_absolute_percentage_error: 349350.9688\n",
            "Epoch 43/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0026 - mean_absolute_error: 0.0341 - mean_absolute_percentage_error: 436046.9688 - val_loss: 0.0023 - val_mean_absolute_error: 0.0338 - val_mean_absolute_percentage_error: 369604.4688\n",
            "Epoch 44/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0026 - mean_absolute_error: 0.0341 - mean_absolute_percentage_error: 434946.9688 - val_loss: 0.0023 - val_mean_absolute_error: 0.0336 - val_mean_absolute_percentage_error: 349303.6875\n",
            "Epoch 45/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0026 - mean_absolute_error: 0.0339 - mean_absolute_percentage_error: 425659.3750 - val_loss: 0.0023 - val_mean_absolute_error: 0.0336 - val_mean_absolute_percentage_error: 397599.5938\n",
            "Epoch 46/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0026 - mean_absolute_error: 0.0339 - mean_absolute_percentage_error: 420202.0000 - val_loss: 0.0023 - val_mean_absolute_error: 0.0336 - val_mean_absolute_percentage_error: 457045.3438\n",
            "Epoch 47/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0026 - mean_absolute_error: 0.0339 - mean_absolute_percentage_error: 415517.9375 - val_loss: 0.0023 - val_mean_absolute_error: 0.0344 - val_mean_absolute_percentage_error: 448651.1875\n",
            "Epoch 48/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0026 - mean_absolute_error: 0.0338 - mean_absolute_percentage_error: 428502.4062 - val_loss: 0.0023 - val_mean_absolute_error: 0.0336 - val_mean_absolute_percentage_error: 408852.8750\n",
            "Epoch 49/100\n",
            "70487/70487 [==============================] - 8s 106us/sample - loss: 0.0026 - mean_absolute_error: 0.0338 - mean_absolute_percentage_error: 410154.1562 - val_loss: 0.0024 - val_mean_absolute_error: 0.0343 - val_mean_absolute_percentage_error: 417662.7188\n",
            "Epoch 50/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0026 - mean_absolute_error: 0.0338 - mean_absolute_percentage_error: 414577.0312 - val_loss: 0.0023 - val_mean_absolute_error: 0.0338 - val_mean_absolute_percentage_error: 506299.3750\n",
            "Epoch 51/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0026 - mean_absolute_error: 0.0337 - mean_absolute_percentage_error: 425861.0312 - val_loss: 0.0023 - val_mean_absolute_error: 0.0336 - val_mean_absolute_percentage_error: 429035.2188\n",
            "Epoch 52/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0026 - mean_absolute_error: 0.0336 - mean_absolute_percentage_error: 406855.4688 - val_loss: 0.0023 - val_mean_absolute_error: 0.0338 - val_mean_absolute_percentage_error: 392917.1250\n",
            "Epoch 53/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0025 - mean_absolute_error: 0.0336 - mean_absolute_percentage_error: 403857.6875 - val_loss: 0.0023 - val_mean_absolute_error: 0.0340 - val_mean_absolute_percentage_error: 580528.3750\n",
            "Epoch 54/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0025 - mean_absolute_error: 0.0335 - mean_absolute_percentage_error: 408821.0000 - val_loss: 0.0023 - val_mean_absolute_error: 0.0334 - val_mean_absolute_percentage_error: 358581.7812\n",
            "Epoch 55/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0025 - mean_absolute_error: 0.0335 - mean_absolute_percentage_error: 406033.7500 - val_loss: 0.0023 - val_mean_absolute_error: 0.0336 - val_mean_absolute_percentage_error: 441741.0000\n",
            "Epoch 56/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0025 - mean_absolute_error: 0.0335 - mean_absolute_percentage_error: 415691.4062 - val_loss: 0.0023 - val_mean_absolute_error: 0.0335 - val_mean_absolute_percentage_error: 350427.3125\n",
            "Epoch 57/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0025 - mean_absolute_error: 0.0334 - mean_absolute_percentage_error: 393888.2812 - val_loss: 0.0023 - val_mean_absolute_error: 0.0334 - val_mean_absolute_percentage_error: 345358.6875\n",
            "Epoch 58/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0025 - mean_absolute_error: 0.0334 - mean_absolute_percentage_error: 406400.9688 - val_loss: 0.0023 - val_mean_absolute_error: 0.0337 - val_mean_absolute_percentage_error: 373224.9375\n",
            "Epoch 59/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0025 - mean_absolute_error: 0.0334 - mean_absolute_percentage_error: 407180.3750 - val_loss: 0.0023 - val_mean_absolute_error: 0.0333 - val_mean_absolute_percentage_error: 385596.4062\n",
            "Epoch 60/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0025 - mean_absolute_error: 0.0332 - mean_absolute_percentage_error: 405474.8750 - val_loss: 0.0023 - val_mean_absolute_error: 0.0337 - val_mean_absolute_percentage_error: 460177.3125\n",
            "Epoch 61/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0025 - mean_absolute_error: 0.0333 - mean_absolute_percentage_error: 410687.5625 - val_loss: 0.0023 - val_mean_absolute_error: 0.0337 - val_mean_absolute_percentage_error: 502691.7500\n",
            "Epoch 62/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0025 - mean_absolute_error: 0.0333 - mean_absolute_percentage_error: 409742.5000 - val_loss: 0.0023 - val_mean_absolute_error: 0.0336 - val_mean_absolute_percentage_error: 324733.2500\n",
            "Epoch 63/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0025 - mean_absolute_error: 0.0332 - mean_absolute_percentage_error: 407036.0312 - val_loss: 0.0023 - val_mean_absolute_error: 0.0339 - val_mean_absolute_percentage_error: 444506.8125\n",
            "Epoch 64/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0025 - mean_absolute_error: 0.0332 - mean_absolute_percentage_error: 407660.5000 - val_loss: 0.0023 - val_mean_absolute_error: 0.0334 - val_mean_absolute_percentage_error: 419413.2500\n",
            "Epoch 65/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0025 - mean_absolute_error: 0.0331 - mean_absolute_percentage_error: 404362.2812 - val_loss: 0.0023 - val_mean_absolute_error: 0.0332 - val_mean_absolute_percentage_error: 430088.3438\n",
            "Epoch 66/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0025 - mean_absolute_error: 0.0332 - mean_absolute_percentage_error: 408788.4062 - val_loss: 0.0023 - val_mean_absolute_error: 0.0336 - val_mean_absolute_percentage_error: 447594.4688\n",
            "Epoch 67/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0025 - mean_absolute_error: 0.0331 - mean_absolute_percentage_error: 409187.1250 - val_loss: 0.0023 - val_mean_absolute_error: 0.0334 - val_mean_absolute_percentage_error: 373044.0312\n",
            "Epoch 68/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0025 - mean_absolute_error: 0.0330 - mean_absolute_percentage_error: 408055.3750 - val_loss: 0.0023 - val_mean_absolute_error: 0.0335 - val_mean_absolute_percentage_error: 414054.9062\n",
            "Epoch 69/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0024 - mean_absolute_error: 0.0329 - mean_absolute_percentage_error: 412069.3750 - val_loss: 0.0023 - val_mean_absolute_error: 0.0336 - val_mean_absolute_percentage_error: 392736.1875\n",
            "Epoch 70/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0024 - mean_absolute_error: 0.0329 - mean_absolute_percentage_error: 427052.2188 - val_loss: 0.0023 - val_mean_absolute_error: 0.0337 - val_mean_absolute_percentage_error: 429952.4062\n",
            "Epoch 71/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0024 - mean_absolute_error: 0.0328 - mean_absolute_percentage_error: 420904.6875 - val_loss: 0.0024 - val_mean_absolute_error: 0.0342 - val_mean_absolute_percentage_error: 456587.4062\n",
            "Epoch 72/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0024 - mean_absolute_error: 0.0328 - mean_absolute_percentage_error: 451768.8125 - val_loss: 0.0023 - val_mean_absolute_error: 0.0333 - val_mean_absolute_percentage_error: 477184.0625\n",
            "Epoch 73/100\n",
            "70487/70487 [==============================] - 8s 106us/sample - loss: 0.0024 - mean_absolute_error: 0.0328 - mean_absolute_percentage_error: 438085.5312 - val_loss: 0.0023 - val_mean_absolute_error: 0.0333 - val_mean_absolute_percentage_error: 423099.9688\n",
            "Epoch 74/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0024 - mean_absolute_error: 0.0327 - mean_absolute_percentage_error: 447855.4688 - val_loss: 0.0023 - val_mean_absolute_error: 0.0335 - val_mean_absolute_percentage_error: 406459.8125\n",
            "Epoch 75/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0024 - mean_absolute_error: 0.0326 - mean_absolute_percentage_error: 449113.4688 - val_loss: 0.0023 - val_mean_absolute_error: 0.0334 - val_mean_absolute_percentage_error: 509823.8125\n",
            "Epoch 76/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0024 - mean_absolute_error: 0.0325 - mean_absolute_percentage_error: 447672.4688 - val_loss: 0.0023 - val_mean_absolute_error: 0.0337 - val_mean_absolute_percentage_error: 457105.3750\n",
            "Epoch 77/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0024 - mean_absolute_error: 0.0325 - mean_absolute_percentage_error: 455685.6562 - val_loss: 0.0022 - val_mean_absolute_error: 0.0333 - val_mean_absolute_percentage_error: 544611.0000\n",
            "Epoch 78/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0024 - mean_absolute_error: 0.0324 - mean_absolute_percentage_error: 462110.7500 - val_loss: 0.0023 - val_mean_absolute_error: 0.0334 - val_mean_absolute_percentage_error: 470561.3750\n",
            "Epoch 79/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0024 - mean_absolute_error: 0.0323 - mean_absolute_percentage_error: 467594.6562 - val_loss: 0.0023 - val_mean_absolute_error: 0.0335 - val_mean_absolute_percentage_error: 446188.0000\n",
            "Epoch 80/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0023 - mean_absolute_error: 0.0323 - mean_absolute_percentage_error: 466895.6562 - val_loss: 0.0023 - val_mean_absolute_error: 0.0338 - val_mean_absolute_percentage_error: 457382.5000\n",
            "Epoch 81/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0023 - mean_absolute_error: 0.0322 - mean_absolute_percentage_error: 461866.4062 - val_loss: 0.0023 - val_mean_absolute_error: 0.0334 - val_mean_absolute_percentage_error: 482273.2500\n",
            "Epoch 82/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0023 - mean_absolute_error: 0.0322 - mean_absolute_percentage_error: 465130.5938 - val_loss: 0.0023 - val_mean_absolute_error: 0.0332 - val_mean_absolute_percentage_error: 489285.6250\n",
            "Epoch 83/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0023 - mean_absolute_error: 0.0321 - mean_absolute_percentage_error: 466119.8750 - val_loss: 0.0023 - val_mean_absolute_error: 0.0331 - val_mean_absolute_percentage_error: 447889.9062\n",
            "Epoch 84/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0023 - mean_absolute_error: 0.0321 - mean_absolute_percentage_error: 468165.7188 - val_loss: 0.0023 - val_mean_absolute_error: 0.0334 - val_mean_absolute_percentage_error: 453909.8750\n",
            "Epoch 85/100\n",
            "70487/70487 [==============================] - 8s 106us/sample - loss: 0.0023 - mean_absolute_error: 0.0320 - mean_absolute_percentage_error: 457152.2188 - val_loss: 0.0023 - val_mean_absolute_error: 0.0336 - val_mean_absolute_percentage_error: 435059.3438\n",
            "Epoch 86/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0023 - mean_absolute_error: 0.0320 - mean_absolute_percentage_error: 459605.2812 - val_loss: 0.0023 - val_mean_absolute_error: 0.0335 - val_mean_absolute_percentage_error: 431085.5000\n",
            "Epoch 87/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0023 - mean_absolute_error: 0.0319 - mean_absolute_percentage_error: 456258.5000 - val_loss: 0.0023 - val_mean_absolute_error: 0.0336 - val_mean_absolute_percentage_error: 580487.3125\n",
            "Epoch 88/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0023 - mean_absolute_error: 0.0319 - mean_absolute_percentage_error: 446109.6875 - val_loss: 0.0023 - val_mean_absolute_error: 0.0335 - val_mean_absolute_percentage_error: 473329.1562\n",
            "Epoch 89/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0023 - mean_absolute_error: 0.0318 - mean_absolute_percentage_error: 436184.4375 - val_loss: 0.0023 - val_mean_absolute_error: 0.0333 - val_mean_absolute_percentage_error: 516804.8125\n",
            "Epoch 90/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0023 - mean_absolute_error: 0.0318 - mean_absolute_percentage_error: 436222.8750 - val_loss: 0.0023 - val_mean_absolute_error: 0.0334 - val_mean_absolute_percentage_error: 492837.3750\n",
            "Epoch 91/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0023 - mean_absolute_error: 0.0318 - mean_absolute_percentage_error: 429338.4062 - val_loss: 0.0023 - val_mean_absolute_error: 0.0335 - val_mean_absolute_percentage_error: 429429.4062\n",
            "Epoch 92/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0023 - mean_absolute_error: 0.0317 - mean_absolute_percentage_error: 419916.2812 - val_loss: 0.0023 - val_mean_absolute_error: 0.0337 - val_mean_absolute_percentage_error: 409311.7500\n",
            "Epoch 93/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0022 - mean_absolute_error: 0.0316 - mean_absolute_percentage_error: 412613.5938 - val_loss: 0.0023 - val_mean_absolute_error: 0.0339 - val_mean_absolute_percentage_error: 482726.9688\n",
            "Epoch 94/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0022 - mean_absolute_error: 0.0316 - mean_absolute_percentage_error: 410011.9688 - val_loss: 0.0023 - val_mean_absolute_error: 0.0337 - val_mean_absolute_percentage_error: 425370.8125\n",
            "Epoch 95/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0022 - mean_absolute_error: 0.0315 - mean_absolute_percentage_error: 410414.5625 - val_loss: 0.0023 - val_mean_absolute_error: 0.0335 - val_mean_absolute_percentage_error: 392767.3438\n",
            "Epoch 96/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0022 - mean_absolute_error: 0.0315 - mean_absolute_percentage_error: 405028.8125 - val_loss: 0.0023 - val_mean_absolute_error: 0.0337 - val_mean_absolute_percentage_error: 443704.2500\n",
            "Epoch 97/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0022 - mean_absolute_error: 0.0315 - mean_absolute_percentage_error: 407471.2188 - val_loss: 0.0023 - val_mean_absolute_error: 0.0334 - val_mean_absolute_percentage_error: 399703.8125\n",
            "Epoch 98/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0022 - mean_absolute_error: 0.0314 - mean_absolute_percentage_error: 411825.5625 - val_loss: 0.0023 - val_mean_absolute_error: 0.0337 - val_mean_absolute_percentage_error: 464334.6875\n",
            "Epoch 99/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0022 - mean_absolute_error: 0.0314 - mean_absolute_percentage_error: 411023.0625 - val_loss: 0.0023 - val_mean_absolute_error: 0.0336 - val_mean_absolute_percentage_error: 472436.0625\n",
            "Epoch 100/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0022 - mean_absolute_error: 0.0313 - mean_absolute_percentage_error: 402358.9375 - val_loss: 0.0023 - val_mean_absolute_error: 0.0336 - val_mean_absolute_percentage_error: 390472.2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lay9lKHJLUR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17a0a3ec-d786-4b13-b35f-a934dcd1f674"
      },
      "source": [
        "m, enc, dec = seq2seq(history, future, latent_dim=50, num_features=4, mn=.5)\n",
        "m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4, clipvalue=1.0), loss=MAE, metrics=[MSE])\n",
        "h = m.fit(x=train_data[0], y=train_data[1], batch_size=train_batch, epochs=100, \n",
        "          validation_data=vad_data)\n",
        "plot_train_history(h, 'Seq2Seq 50 dimensions, Adam lr=5e-4 y mn=0.5')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_model_inference\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, 4)]         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 50)          11000     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                [(None, 50), (None, 50),  20200     \n",
            "=================================================================\n",
            "Total params: 31,200\n",
            "Trainable params: 31,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"decoder_model_inference\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 50), ( 10400       input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 1)      51          lstm_2[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"seq2seq_training_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 4)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, None, 50)     11000       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 50), (None,  20200       lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 50), ( 10400       input_2[0][0]                    \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 1)      51          lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 41,651\n",
            "Trainable params: 41,651\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 70487 samples, validate on 9116 samples\n",
            "Epoch 1/100\n",
            "70487/70487 [==============================] - 14s 195us/sample - loss: 0.1686 - mean_squared_error: 0.0533 - val_loss: 0.1044 - val_mean_squared_error: 0.0203\n",
            "Epoch 2/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0822 - mean_squared_error: 0.0137 - val_loss: 0.0698 - val_mean_squared_error: 0.0094\n",
            "Epoch 3/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0629 - mean_squared_error: 0.0081 - val_loss: 0.0569 - val_mean_squared_error: 0.0062\n",
            "Epoch 4/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0531 - mean_squared_error: 0.0059 - val_loss: 0.0495 - val_mean_squared_error: 0.0049\n",
            "Epoch 5/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0474 - mean_squared_error: 0.0048 - val_loss: 0.0446 - val_mean_squared_error: 0.0040\n",
            "Epoch 6/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0439 - mean_squared_error: 0.0042 - val_loss: 0.0425 - val_mean_squared_error: 0.0036\n",
            "Epoch 7/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0419 - mean_squared_error: 0.0039 - val_loss: 0.0405 - val_mean_squared_error: 0.0033\n",
            "Epoch 8/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0406 - mean_squared_error: 0.0037 - val_loss: 0.0396 - val_mean_squared_error: 0.0032\n",
            "Epoch 9/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0397 - mean_squared_error: 0.0036 - val_loss: 0.0394 - val_mean_squared_error: 0.0032\n",
            "Epoch 10/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0392 - mean_squared_error: 0.0035 - val_loss: 0.0390 - val_mean_squared_error: 0.0031\n",
            "Epoch 11/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0388 - mean_squared_error: 0.0034 - val_loss: 0.0388 - val_mean_squared_error: 0.0031\n",
            "Epoch 12/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0384 - mean_squared_error: 0.0034 - val_loss: 0.0386 - val_mean_squared_error: 0.0030\n",
            "Epoch 13/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0379 - mean_squared_error: 0.0033 - val_loss: 0.0372 - val_mean_squared_error: 0.0029\n",
            "Epoch 14/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0377 - mean_squared_error: 0.0033 - val_loss: 0.0370 - val_mean_squared_error: 0.0029\n",
            "Epoch 15/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0374 - mean_squared_error: 0.0033 - val_loss: 0.0370 - val_mean_squared_error: 0.0028\n",
            "Epoch 16/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0373 - mean_squared_error: 0.0032 - val_loss: 0.0368 - val_mean_squared_error: 0.0029\n",
            "Epoch 17/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0371 - mean_squared_error: 0.0032 - val_loss: 0.0364 - val_mean_squared_error: 0.0028\n",
            "Epoch 18/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0370 - mean_squared_error: 0.0032 - val_loss: 0.0370 - val_mean_squared_error: 0.0029\n",
            "Epoch 19/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0370 - mean_squared_error: 0.0032 - val_loss: 0.0364 - val_mean_squared_error: 0.0028\n",
            "Epoch 20/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0368 - mean_squared_error: 0.0032 - val_loss: 0.0362 - val_mean_squared_error: 0.0028\n",
            "Epoch 21/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0367 - mean_squared_error: 0.0031 - val_loss: 0.0364 - val_mean_squared_error: 0.0028\n",
            "Epoch 22/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0366 - mean_squared_error: 0.0031 - val_loss: 0.0361 - val_mean_squared_error: 0.0028\n",
            "Epoch 23/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0365 - mean_squared_error: 0.0031 - val_loss: 0.0364 - val_mean_squared_error: 0.0028\n",
            "Epoch 24/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0364 - mean_squared_error: 0.0031 - val_loss: 0.0362 - val_mean_squared_error: 0.0028\n",
            "Epoch 25/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0364 - mean_squared_error: 0.0031 - val_loss: 0.0358 - val_mean_squared_error: 0.0027\n",
            "Epoch 26/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0362 - mean_squared_error: 0.0031 - val_loss: 0.0364 - val_mean_squared_error: 0.0028\n",
            "Epoch 27/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0361 - mean_squared_error: 0.0031 - val_loss: 0.0357 - val_mean_squared_error: 0.0027\n",
            "Epoch 28/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0359 - mean_squared_error: 0.0030 - val_loss: 0.0356 - val_mean_squared_error: 0.0027\n",
            "Epoch 29/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0359 - mean_squared_error: 0.0030 - val_loss: 0.0355 - val_mean_squared_error: 0.0027\n",
            "Epoch 30/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0357 - mean_squared_error: 0.0030 - val_loss: 0.0353 - val_mean_squared_error: 0.0026\n",
            "Epoch 31/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0356 - mean_squared_error: 0.0030 - val_loss: 0.0353 - val_mean_squared_error: 0.0027\n",
            "Epoch 32/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0355 - mean_squared_error: 0.0030 - val_loss: 0.0352 - val_mean_squared_error: 0.0026\n",
            "Epoch 33/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0355 - mean_squared_error: 0.0030 - val_loss: 0.0350 - val_mean_squared_error: 0.0026\n",
            "Epoch 34/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0354 - mean_squared_error: 0.0030 - val_loss: 0.0350 - val_mean_squared_error: 0.0026\n",
            "Epoch 35/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0352 - mean_squared_error: 0.0029 - val_loss: 0.0352 - val_mean_squared_error: 0.0026\n",
            "Epoch 36/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0352 - mean_squared_error: 0.0029 - val_loss: 0.0351 - val_mean_squared_error: 0.0026\n",
            "Epoch 37/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0351 - mean_squared_error: 0.0029 - val_loss: 0.0348 - val_mean_squared_error: 0.0026\n",
            "Epoch 38/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0350 - mean_squared_error: 0.0029 - val_loss: 0.0347 - val_mean_squared_error: 0.0026\n",
            "Epoch 39/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0350 - mean_squared_error: 0.0029 - val_loss: 0.0347 - val_mean_squared_error: 0.0026\n",
            "Epoch 40/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0349 - mean_squared_error: 0.0029 - val_loss: 0.0346 - val_mean_squared_error: 0.0026\n",
            "Epoch 41/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0349 - mean_squared_error: 0.0029 - val_loss: 0.0349 - val_mean_squared_error: 0.0026\n",
            "Epoch 42/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0348 - mean_squared_error: 0.0029 - val_loss: 0.0347 - val_mean_squared_error: 0.0026\n",
            "Epoch 43/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0347 - mean_squared_error: 0.0029 - val_loss: 0.0346 - val_mean_squared_error: 0.0025\n",
            "Epoch 44/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0346 - mean_squared_error: 0.0029 - val_loss: 0.0344 - val_mean_squared_error: 0.0025\n",
            "Epoch 45/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0345 - mean_squared_error: 0.0028 - val_loss: 0.0343 - val_mean_squared_error: 0.0025\n",
            "Epoch 46/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0344 - mean_squared_error: 0.0028 - val_loss: 0.0349 - val_mean_squared_error: 0.0025\n",
            "Epoch 47/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0342 - mean_squared_error: 0.0028 - val_loss: 0.0339 - val_mean_squared_error: 0.0025\n",
            "Epoch 48/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0341 - mean_squared_error: 0.0028 - val_loss: 0.0342 - val_mean_squared_error: 0.0025\n",
            "Epoch 49/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0339 - mean_squared_error: 0.0028 - val_loss: 0.0338 - val_mean_squared_error: 0.0024\n",
            "Epoch 50/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0337 - mean_squared_error: 0.0027 - val_loss: 0.0339 - val_mean_squared_error: 0.0025\n",
            "Epoch 51/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0337 - mean_squared_error: 0.0027 - val_loss: 0.0339 - val_mean_squared_error: 0.0024\n",
            "Epoch 52/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0335 - mean_squared_error: 0.0027 - val_loss: 0.0336 - val_mean_squared_error: 0.0024\n",
            "Epoch 53/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0333 - mean_squared_error: 0.0027 - val_loss: 0.0340 - val_mean_squared_error: 0.0025\n",
            "Epoch 54/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0333 - mean_squared_error: 0.0027 - val_loss: 0.0334 - val_mean_squared_error: 0.0024\n",
            "Epoch 55/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0332 - mean_squared_error: 0.0027 - val_loss: 0.0335 - val_mean_squared_error: 0.0024\n",
            "Epoch 56/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0331 - mean_squared_error: 0.0026 - val_loss: 0.0334 - val_mean_squared_error: 0.0024\n",
            "Epoch 57/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0331 - mean_squared_error: 0.0026 - val_loss: 0.0336 - val_mean_squared_error: 0.0024\n",
            "Epoch 58/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0329 - mean_squared_error: 0.0026 - val_loss: 0.0336 - val_mean_squared_error: 0.0024\n",
            "Epoch 59/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0329 - mean_squared_error: 0.0026 - val_loss: 0.0331 - val_mean_squared_error: 0.0024\n",
            "Epoch 60/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0328 - mean_squared_error: 0.0026 - val_loss: 0.0334 - val_mean_squared_error: 0.0024\n",
            "Epoch 61/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0328 - mean_squared_error: 0.0026 - val_loss: 0.0332 - val_mean_squared_error: 0.0024\n",
            "Epoch 62/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0327 - mean_squared_error: 0.0026 - val_loss: 0.0331 - val_mean_squared_error: 0.0023\n",
            "Epoch 63/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0327 - mean_squared_error: 0.0026 - val_loss: 0.0336 - val_mean_squared_error: 0.0024\n",
            "Epoch 64/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0326 - mean_squared_error: 0.0026 - val_loss: 0.0335 - val_mean_squared_error: 0.0024\n",
            "Epoch 65/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0326 - mean_squared_error: 0.0026 - val_loss: 0.0329 - val_mean_squared_error: 0.0023\n",
            "Epoch 66/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0324 - mean_squared_error: 0.0026 - val_loss: 0.0332 - val_mean_squared_error: 0.0024\n",
            "Epoch 67/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0324 - mean_squared_error: 0.0025 - val_loss: 0.0333 - val_mean_squared_error: 0.0024\n",
            "Epoch 68/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0322 - mean_squared_error: 0.0025 - val_loss: 0.0334 - val_mean_squared_error: 0.0024\n",
            "Epoch 69/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0322 - mean_squared_error: 0.0025 - val_loss: 0.0334 - val_mean_squared_error: 0.0024\n",
            "Epoch 70/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0322 - mean_squared_error: 0.0025 - val_loss: 0.0333 - val_mean_squared_error: 0.0024\n",
            "Epoch 71/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0321 - mean_squared_error: 0.0025 - val_loss: 0.0332 - val_mean_squared_error: 0.0024\n",
            "Epoch 72/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0320 - mean_squared_error: 0.0025 - val_loss: 0.0333 - val_mean_squared_error: 0.0024\n",
            "Epoch 73/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0320 - mean_squared_error: 0.0025 - val_loss: 0.0334 - val_mean_squared_error: 0.0024\n",
            "Epoch 74/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0319 - mean_squared_error: 0.0025 - val_loss: 0.0335 - val_mean_squared_error: 0.0024\n",
            "Epoch 75/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0318 - mean_squared_error: 0.0025 - val_loss: 0.0333 - val_mean_squared_error: 0.0024\n",
            "Epoch 76/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0318 - mean_squared_error: 0.0025 - val_loss: 0.0337 - val_mean_squared_error: 0.0024\n",
            "Epoch 77/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0317 - mean_squared_error: 0.0025 - val_loss: 0.0333 - val_mean_squared_error: 0.0024\n",
            "Epoch 78/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0316 - mean_squared_error: 0.0025 - val_loss: 0.0334 - val_mean_squared_error: 0.0024\n",
            "Epoch 79/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0316 - mean_squared_error: 0.0024 - val_loss: 0.0334 - val_mean_squared_error: 0.0024\n",
            "Epoch 80/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0315 - mean_squared_error: 0.0024 - val_loss: 0.0337 - val_mean_squared_error: 0.0024\n",
            "Epoch 81/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0314 - mean_squared_error: 0.0024 - val_loss: 0.0336 - val_mean_squared_error: 0.0024\n",
            "Epoch 82/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0314 - mean_squared_error: 0.0024 - val_loss: 0.0335 - val_mean_squared_error: 0.0024\n",
            "Epoch 83/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0314 - mean_squared_error: 0.0024 - val_loss: 0.0337 - val_mean_squared_error: 0.0024\n",
            "Epoch 84/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0313 - mean_squared_error: 0.0024 - val_loss: 0.0339 - val_mean_squared_error: 0.0025\n",
            "Epoch 85/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0313 - mean_squared_error: 0.0024 - val_loss: 0.0336 - val_mean_squared_error: 0.0024\n",
            "Epoch 86/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0312 - mean_squared_error: 0.0024 - val_loss: 0.0341 - val_mean_squared_error: 0.0025\n",
            "Epoch 87/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0311 - mean_squared_error: 0.0024 - val_loss: 0.0338 - val_mean_squared_error: 0.0024\n",
            "Epoch 88/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0311 - mean_squared_error: 0.0024 - val_loss: 0.0337 - val_mean_squared_error: 0.0025\n",
            "Epoch 89/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0310 - mean_squared_error: 0.0024 - val_loss: 0.0341 - val_mean_squared_error: 0.0025\n",
            "Epoch 90/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0310 - mean_squared_error: 0.0024 - val_loss: 0.0338 - val_mean_squared_error: 0.0025\n",
            "Epoch 91/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0309 - mean_squared_error: 0.0024 - val_loss: 0.0341 - val_mean_squared_error: 0.0025\n",
            "Epoch 92/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0309 - mean_squared_error: 0.0024 - val_loss: 0.0341 - val_mean_squared_error: 0.0024\n",
            "Epoch 93/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0308 - mean_squared_error: 0.0024 - val_loss: 0.0338 - val_mean_squared_error: 0.0025\n",
            "Epoch 94/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0308 - mean_squared_error: 0.0023 - val_loss: 0.0339 - val_mean_squared_error: 0.0025\n",
            "Epoch 95/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0307 - mean_squared_error: 0.0023 - val_loss: 0.0338 - val_mean_squared_error: 0.0025\n",
            "Epoch 96/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0306 - mean_squared_error: 0.0023 - val_loss: 0.0340 - val_mean_squared_error: 0.0025\n",
            "Epoch 97/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0305 - mean_squared_error: 0.0023 - val_loss: 0.0345 - val_mean_squared_error: 0.0025\n",
            "Epoch 98/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0305 - mean_squared_error: 0.0023 - val_loss: 0.0342 - val_mean_squared_error: 0.0025\n",
            "Epoch 99/100\n",
            "70487/70487 [==============================] - 7s 103us/sample - loss: 0.0305 - mean_squared_error: 0.0023 - val_loss: 0.0340 - val_mean_squared_error: 0.0025\n",
            "Epoch 100/100\n",
            "70487/70487 [==============================] - 7s 104us/sample - loss: 0.0304 - mean_squared_error: 0.0023 - val_loss: 0.0344 - val_mean_squared_error: 0.0025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJAGcdKZQvkC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3d60a928-b180-43df-bab8-e9b8339fec71"
      },
      "source": [
        "m, enc, dec = seq2seq(history, future, latent_dim=50, num_features=4, mn=.3)\n",
        "m.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3, clipvalue=1.0), loss=MAE, metrics=[MSE])\n",
        "h = m.fit(x=train_data[0], y=train_data[1], batch_size=train_batch, epochs=100, \n",
        "          validation_data=vad_data)\n",
        "plot_train_history(h, 'Seq2Seq 50 dimensions, RmsProp lr=1e-3 y mn=0.3')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_model_inference\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, 4)]         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 50)          11000     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                [(None, 50), (None, 50),  20200     \n",
            "=================================================================\n",
            "Total params: 31,200\n",
            "Trainable params: 31,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"decoder_model_inference\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 50), ( 10400       input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 1)      51          lstm_2[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"seq2seq_training_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 4)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, None, 50)     11000       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 50), (None,  20200       lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 50), ( 10400       input_2[0][0]                    \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 1)      51          lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 41,651\n",
            "Trainable params: 41,651\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 70487 samples, validate on 9116 samples\n",
            "Epoch 1/100\n",
            "70487/70487 [==============================] - 14s 201us/sample - loss: 0.1550 - mean_squared_error: 0.0437 - val_loss: 0.1082 - val_mean_squared_error: 0.0206\n",
            "Epoch 2/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0986 - mean_squared_error: 0.0192 - val_loss: 0.0951 - val_mean_squared_error: 0.0181\n",
            "Epoch 3/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0854 - mean_squared_error: 0.0149 - val_loss: 0.0811 - val_mean_squared_error: 0.0143\n",
            "Epoch 4/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0778 - mean_squared_error: 0.0125 - val_loss: 0.0711 - val_mean_squared_error: 0.0096\n",
            "Epoch 5/100\n",
            "70487/70487 [==============================] - 8s 106us/sample - loss: 0.0731 - mean_squared_error: 0.0113 - val_loss: 0.0780 - val_mean_squared_error: 0.0142\n",
            "Epoch 6/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0698 - mean_squared_error: 0.0103 - val_loss: 0.0708 - val_mean_squared_error: 0.0097\n",
            "Epoch 7/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0670 - mean_squared_error: 0.0097 - val_loss: 0.0685 - val_mean_squared_error: 0.0087\n",
            "Epoch 8/100\n",
            "70487/70487 [==============================] - 8s 109us/sample - loss: 0.0647 - mean_squared_error: 0.0090 - val_loss: 0.0628 - val_mean_squared_error: 0.0074\n",
            "Epoch 9/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0631 - mean_squared_error: 0.0087 - val_loss: 0.0656 - val_mean_squared_error: 0.0080\n",
            "Epoch 10/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0613 - mean_squared_error: 0.0081 - val_loss: 0.0611 - val_mean_squared_error: 0.0072\n",
            "Epoch 11/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0601 - mean_squared_error: 0.0078 - val_loss: 0.0582 - val_mean_squared_error: 0.0066\n",
            "Epoch 12/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0589 - mean_squared_error: 0.0076 - val_loss: 0.0563 - val_mean_squared_error: 0.0063\n",
            "Epoch 13/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0579 - mean_squared_error: 0.0074 - val_loss: 0.0567 - val_mean_squared_error: 0.0062\n",
            "Epoch 14/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0569 - mean_squared_error: 0.0071 - val_loss: 0.0562 - val_mean_squared_error: 0.0060\n",
            "Epoch 15/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0561 - mean_squared_error: 0.0070 - val_loss: 0.0566 - val_mean_squared_error: 0.0061\n",
            "Epoch 16/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0555 - mean_squared_error: 0.0069 - val_loss: 0.0518 - val_mean_squared_error: 0.0054\n",
            "Epoch 17/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0548 - mean_squared_error: 0.0067 - val_loss: 0.0565 - val_mean_squared_error: 0.0063\n",
            "Epoch 18/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0543 - mean_squared_error: 0.0066 - val_loss: 0.0533 - val_mean_squared_error: 0.0058\n",
            "Epoch 19/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0535 - mean_squared_error: 0.0063 - val_loss: 0.0564 - val_mean_squared_error: 0.0061\n",
            "Epoch 20/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0532 - mean_squared_error: 0.0063 - val_loss: 0.0510 - val_mean_squared_error: 0.0051\n",
            "Epoch 21/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0527 - mean_squared_error: 0.0063 - val_loss: 0.0513 - val_mean_squared_error: 0.0053\n",
            "Epoch 22/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0523 - mean_squared_error: 0.0061 - val_loss: 0.0503 - val_mean_squared_error: 0.0051\n",
            "Epoch 23/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0521 - mean_squared_error: 0.0061 - val_loss: 0.0525 - val_mean_squared_error: 0.0056\n",
            "Epoch 24/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0517 - mean_squared_error: 0.0060 - val_loss: 0.0500 - val_mean_squared_error: 0.0051\n",
            "Epoch 25/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0513 - mean_squared_error: 0.0059 - val_loss: 0.0508 - val_mean_squared_error: 0.0052\n",
            "Epoch 26/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0512 - mean_squared_error: 0.0059 - val_loss: 0.0512 - val_mean_squared_error: 0.0053\n",
            "Epoch 27/100\n",
            "70487/70487 [==============================] - 8s 106us/sample - loss: 0.0508 - mean_squared_error: 0.0058 - val_loss: 0.0536 - val_mean_squared_error: 0.0057\n",
            "Epoch 28/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0506 - mean_squared_error: 0.0058 - val_loss: 0.0511 - val_mean_squared_error: 0.0053\n",
            "Epoch 29/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0504 - mean_squared_error: 0.0057 - val_loss: 0.0507 - val_mean_squared_error: 0.0053\n",
            "Epoch 30/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0502 - mean_squared_error: 0.0056 - val_loss: 0.0518 - val_mean_squared_error: 0.0051\n",
            "Epoch 31/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0500 - mean_squared_error: 0.0056 - val_loss: 0.0494 - val_mean_squared_error: 0.0049\n",
            "Epoch 32/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0498 - mean_squared_error: 0.0056 - val_loss: 0.0516 - val_mean_squared_error: 0.0054\n",
            "Epoch 33/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0496 - mean_squared_error: 0.0055 - val_loss: 0.0511 - val_mean_squared_error: 0.0050\n",
            "Epoch 34/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0495 - mean_squared_error: 0.0055 - val_loss: 0.0518 - val_mean_squared_error: 0.0053\n",
            "Epoch 35/100\n",
            "70487/70487 [==============================] - 8s 108us/sample - loss: 0.0493 - mean_squared_error: 0.0055 - val_loss: 0.0498 - val_mean_squared_error: 0.0049\n",
            "Epoch 36/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0490 - mean_squared_error: 0.0054 - val_loss: 0.0507 - val_mean_squared_error: 0.0052\n",
            "Epoch 37/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0489 - mean_squared_error: 0.0054 - val_loss: 0.0518 - val_mean_squared_error: 0.0053\n",
            "Epoch 38/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0488 - mean_squared_error: 0.0054 - val_loss: 0.0517 - val_mean_squared_error: 0.0051\n",
            "Epoch 39/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0487 - mean_squared_error: 0.0053 - val_loss: 0.0499 - val_mean_squared_error: 0.0052\n",
            "Epoch 40/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0485 - mean_squared_error: 0.0053 - val_loss: 0.0540 - val_mean_squared_error: 0.0058\n",
            "Epoch 41/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0484 - mean_squared_error: 0.0053 - val_loss: 0.0524 - val_mean_squared_error: 0.0055\n",
            "Epoch 42/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0484 - mean_squared_error: 0.0053 - val_loss: 0.0513 - val_mean_squared_error: 0.0054\n",
            "Epoch 43/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0484 - mean_squared_error: 0.0052 - val_loss: 0.0511 - val_mean_squared_error: 0.0052\n",
            "Epoch 44/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0482 - mean_squared_error: 0.0052 - val_loss: 0.0509 - val_mean_squared_error: 0.0053\n",
            "Epoch 45/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0482 - mean_squared_error: 0.0052 - val_loss: 0.0560 - val_mean_squared_error: 0.0071\n",
            "Epoch 46/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0482 - mean_squared_error: 0.0052 - val_loss: 0.0509 - val_mean_squared_error: 0.0052\n",
            "Epoch 47/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0482 - mean_squared_error: 0.0052 - val_loss: 0.0517 - val_mean_squared_error: 0.0053\n",
            "Epoch 48/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0481 - mean_squared_error: 0.0052 - val_loss: 0.0533 - val_mean_squared_error: 0.0058\n",
            "Epoch 49/100\n",
            "70487/70487 [==============================] - 8s 109us/sample - loss: 0.0481 - mean_squared_error: 0.0052 - val_loss: 0.0533 - val_mean_squared_error: 0.0057\n",
            "Epoch 50/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0480 - mean_squared_error: 0.0052 - val_loss: 0.0540 - val_mean_squared_error: 0.0057\n",
            "Epoch 51/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0478 - mean_squared_error: 0.0051 - val_loss: 0.0556 - val_mean_squared_error: 0.0058\n",
            "Epoch 52/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0476 - mean_squared_error: 0.0050 - val_loss: 0.0542 - val_mean_squared_error: 0.0059\n",
            "Epoch 53/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0475 - mean_squared_error: 0.0050 - val_loss: 0.0540 - val_mean_squared_error: 0.0059\n",
            "Epoch 54/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0474 - mean_squared_error: 0.0050 - val_loss: 0.0580 - val_mean_squared_error: 0.0094\n",
            "Epoch 55/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0472 - mean_squared_error: 0.0050 - val_loss: 0.0522 - val_mean_squared_error: 0.0055\n",
            "Epoch 56/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0471 - mean_squared_error: 0.0050 - val_loss: 0.0514 - val_mean_squared_error: 0.0052\n",
            "Epoch 57/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0469 - mean_squared_error: 0.0049 - val_loss: 0.0532 - val_mean_squared_error: 0.0056\n",
            "Epoch 58/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0469 - mean_squared_error: 0.0049 - val_loss: 0.0554 - val_mean_squared_error: 0.0059\n",
            "Epoch 59/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0468 - mean_squared_error: 0.0049 - val_loss: 0.0507 - val_mean_squared_error: 0.0052\n",
            "Epoch 60/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0466 - mean_squared_error: 0.0048 - val_loss: 0.0525 - val_mean_squared_error: 0.0056\n",
            "Epoch 61/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0465 - mean_squared_error: 0.0049 - val_loss: 0.0529 - val_mean_squared_error: 0.0057\n",
            "Epoch 62/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0463 - mean_squared_error: 0.0048 - val_loss: 0.0514 - val_mean_squared_error: 0.0055\n",
            "Epoch 63/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0462 - mean_squared_error: 0.0048 - val_loss: 0.0518 - val_mean_squared_error: 0.0053\n",
            "Epoch 64/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0460 - mean_squared_error: 0.0047 - val_loss: 0.0542 - val_mean_squared_error: 0.0058\n",
            "Epoch 65/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0461 - mean_squared_error: 0.0048 - val_loss: 0.0521 - val_mean_squared_error: 0.0055\n",
            "Epoch 66/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0459 - mean_squared_error: 0.0047 - val_loss: 0.0537 - val_mean_squared_error: 0.0055\n",
            "Epoch 67/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0458 - mean_squared_error: 0.0047 - val_loss: 0.0522 - val_mean_squared_error: 0.0053\n",
            "Epoch 68/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0456 - mean_squared_error: 0.0046 - val_loss: 0.0532 - val_mean_squared_error: 0.0058\n",
            "Epoch 69/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0456 - mean_squared_error: 0.0047 - val_loss: 0.0526 - val_mean_squared_error: 0.0055\n",
            "Epoch 70/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0454 - mean_squared_error: 0.0046 - val_loss: 0.0502 - val_mean_squared_error: 0.0052\n",
            "Epoch 71/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0453 - mean_squared_error: 0.0046 - val_loss: 0.0515 - val_mean_squared_error: 0.0054\n",
            "Epoch 72/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0452 - mean_squared_error: 0.0046 - val_loss: 0.0532 - val_mean_squared_error: 0.0058\n",
            "Epoch 73/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0452 - mean_squared_error: 0.0046 - val_loss: 0.0522 - val_mean_squared_error: 0.0057\n",
            "Epoch 74/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0450 - mean_squared_error: 0.0045 - val_loss: 0.0527 - val_mean_squared_error: 0.0058\n",
            "Epoch 75/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0449 - mean_squared_error: 0.0045 - val_loss: 0.0543 - val_mean_squared_error: 0.0057\n",
            "Epoch 76/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0449 - mean_squared_error: 0.0045 - val_loss: 0.0539 - val_mean_squared_error: 0.0057\n",
            "Epoch 77/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0447 - mean_squared_error: 0.0045 - val_loss: 0.0534 - val_mean_squared_error: 0.0058\n",
            "Epoch 78/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0447 - mean_squared_error: 0.0045 - val_loss: 0.0522 - val_mean_squared_error: 0.0055\n",
            "Epoch 79/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0446 - mean_squared_error: 0.0044 - val_loss: 0.0540 - val_mean_squared_error: 0.0059\n",
            "Epoch 80/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0445 - mean_squared_error: 0.0044 - val_loss: 0.0522 - val_mean_squared_error: 0.0057\n",
            "Epoch 81/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0443 - mean_squared_error: 0.0044 - val_loss: 0.0545 - val_mean_squared_error: 0.0057\n",
            "Epoch 82/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0443 - mean_squared_error: 0.0044 - val_loss: 0.0524 - val_mean_squared_error: 0.0056\n",
            "Epoch 83/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0442 - mean_squared_error: 0.0044 - val_loss: 0.0540 - val_mean_squared_error: 0.0060\n",
            "Epoch 84/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0441 - mean_squared_error: 0.0043 - val_loss: 0.0520 - val_mean_squared_error: 0.0056\n",
            "Epoch 85/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0441 - mean_squared_error: 0.0044 - val_loss: 0.0529 - val_mean_squared_error: 0.0056\n",
            "Epoch 86/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0440 - mean_squared_error: 0.0044 - val_loss: 0.0529 - val_mean_squared_error: 0.0059\n",
            "Epoch 87/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0438 - mean_squared_error: 0.0043 - val_loss: 0.0532 - val_mean_squared_error: 0.0055\n",
            "Epoch 88/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0438 - mean_squared_error: 0.0043 - val_loss: 0.0541 - val_mean_squared_error: 0.0058\n",
            "Epoch 89/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0437 - mean_squared_error: 0.0043 - val_loss: 0.0539 - val_mean_squared_error: 0.0057\n",
            "Epoch 90/100\n",
            "70487/70487 [==============================] - 8s 108us/sample - loss: 0.0437 - mean_squared_error: 0.0043 - val_loss: 0.0547 - val_mean_squared_error: 0.0060\n",
            "Epoch 91/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0436 - mean_squared_error: 0.0043 - val_loss: 0.0531 - val_mean_squared_error: 0.0057\n",
            "Epoch 92/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0435 - mean_squared_error: 0.0043 - val_loss: 0.0519 - val_mean_squared_error: 0.0055\n",
            "Epoch 93/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0434 - mean_squared_error: 0.0042 - val_loss: 0.0544 - val_mean_squared_error: 0.0060\n",
            "Epoch 94/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0434 - mean_squared_error: 0.0042 - val_loss: 0.0524 - val_mean_squared_error: 0.0057\n",
            "Epoch 95/100\n",
            "70487/70487 [==============================] - 8s 108us/sample - loss: 0.0433 - mean_squared_error: 0.0042 - val_loss: 0.0542 - val_mean_squared_error: 0.0059\n",
            "Epoch 96/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0432 - mean_squared_error: 0.0042 - val_loss: 0.0564 - val_mean_squared_error: 0.0063\n",
            "Epoch 97/100\n",
            "70487/70487 [==============================] - 8s 107us/sample - loss: 0.0432 - mean_squared_error: 0.0042 - val_loss: 0.0550 - val_mean_squared_error: 0.0057\n",
            "Epoch 98/100\n",
            "70487/70487 [==============================] - 8s 108us/sample - loss: 0.0431 - mean_squared_error: 0.0042 - val_loss: 0.0535 - val_mean_squared_error: 0.0060\n",
            "Epoch 99/100\n",
            "70487/70487 [==============================] - 7s 105us/sample - loss: 0.0430 - mean_squared_error: 0.0042 - val_loss: 0.0578 - val_mean_squared_error: 0.0069\n",
            "Epoch 100/100\n",
            "70487/70487 [==============================] - 7s 106us/sample - loss: 0.0430 - mean_squared_error: 0.0041 - val_loss: 0.0549 - val_mean_squared_error: 0.0060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK63qbvgM0TB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder_simple(latent_dim, num_features, mn):\n",
        "    \"\"\"\n",
        "    Encoder with LSTM \n",
        "\n",
        "    :param latent_dim: dimension of the encoding vectors\n",
        "    :param num_features: number of input features\n",
        "    :param mn: max norm value\n",
        "    :return encoder input and output states, and the inference model\n",
        "    \"\"\"\n",
        "    # Define an input sequence and process it.\n",
        "    encoder_inputs = Input(shape=(None, num_features))\n",
        "    #lstm_enc1 = LSTM(latent_dim, return_sequences=True, kernel_constraint=max_norm(mn))(encoder_inputs)\n",
        "    encoder = LSTM(latent_dim, return_state=True, kernel_constraint=max_norm(mn))\n",
        "    _, state_h, state_c = encoder(encoder_inputs)\n",
        "    # We discard `encoder_outputs` and only keep the states.\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    # model to perform inference with the encoder\n",
        "    encoder_model = Model(inputs=encoder_inputs, \n",
        "                          outputs=encoder_states, \n",
        "                          name='encoder_model_inference')\n",
        "\n",
        "    return encoder_inputs, encoder_states, encoder_model\n",
        "\n",
        "def decoder(encoder_states, latent_dim, mn):\n",
        "    \"\"\"\n",
        "    Decoder with LSTM \n",
        "    \n",
        "    :param encoder_satates: list of tensors with the LSTM states (cell and hidden)\n",
        "    :param latent_dim: dimension of the decoding vectors\n",
        "    :param mn: max norm value\n",
        "    :return decoder input and output sequences, and the inference model\n",
        "    \"\"\"\n",
        "    # Define an input sequence and process it.\n",
        "    # Set up the decoder, using `encoder_states` as initial state.\n",
        "    decoder_inputs = Input(shape=(None, 1))\n",
        "    # We set up our decoder to return full output sequences,\n",
        "    # and to return internal states as well. We don't use the \n",
        "    # return states in the training model, but we will use them in inference.\n",
        "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, \n",
        "                        kernel_constraint=max_norm(mn))\n",
        "    lstm_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "    decoder_dense = Dense(1, activation='selu', kernel_constraint=max_norm(mn))\n",
        "    decoder_outputs = decoder_dense(lstm_outputs)\n",
        "\n",
        "    # model to perform inference with the decoder\n",
        "\n",
        "    # inputs to cell and state (to be feed from the encoder last states, or others!)\n",
        "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "    decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    decoder_outputs_inference, state_h, state_c = decoder_lstm(\n",
        "        decoder_inputs, initial_state=decoder_states_inputs)\n",
        "    \n",
        "    decoder_states_inference = [state_h, state_c]\n",
        "    decoder_outputs_inference = decoder_dense(decoder_outputs_inference)\n",
        "    decoder_model = Model(\n",
        "        inputs=[decoder_inputs] + decoder_states_inputs,\n",
        "        outputs=[decoder_outputs_inference] + decoder_states_inference,\n",
        "        name='decoder_model_inference')\n",
        "    \n",
        "    return decoder_inputs, decoder_outputs, decoder_model\n",
        "\n",
        "def seq2seq_simple(history, future, latent_dim, num_features, mn):\n",
        "    \"\"\"\n",
        "\n",
        "    :param history: number of steps of input sequence\n",
        "    :param future: number of steps of output sequence\n",
        "    :param latent_dim: dimension of the encoding/decoding vectors\n",
        "    :param num_features: number of input features\n",
        "    :param mn: max norm value\n",
        "    :return the model\n",
        "    \"\"\"\n",
        "    clear_session()\n",
        "\n",
        "    # encode\n",
        "    encoder_inputs, encoder_states, encoder_model = encoder_simple(latent_dim, num_features, mn)\n",
        "    print(encoder_model.summary())\n",
        "\n",
        "    # decode\n",
        "    decoder_inputs, decoder_outputs, decoder_model = decoder(encoder_states, latent_dim, mn)\n",
        "    print(decoder_model.summary())\n",
        "\n",
        "    # Training model\n",
        "    training_model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
        "                           outputs=decoder_outputs, \n",
        "                           name='seq2seq_training_model')\n",
        "    print(training_model.summary())\n",
        "\n",
        "    return training_model, encoder_model, decoder_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVJ1PoHCV0ey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70d09812-5753-4ce8-cf94-8f4726f00ea4"
      },
      "source": [
        "m, enc, dec = seq2seq_simple(history, future, latent_dim=50, num_features=4, mn=.5)\n",
        "m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4, clipvalue=1.0), loss=MAE, metrics=[MSE])\n",
        "h = m.fit(x=train_data[0], y=train_data[1], batch_size=train_batch, epochs=100, \n",
        "          validation_data=vad_data)\n",
        "plot_train_history(h, 'Seq2Seq 50 dimensions, Adam lr=5e-4 y mn=0.5')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_model_inference\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, 4)]         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  [(None, 50), (None, 50),  11000     \n",
            "=================================================================\n",
            "Total params: 11,000\n",
            "Trainable params: 11,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"decoder_model_inference\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 50), ( 10400       input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 1)      51          lstm_1[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"seq2seq_training_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 4)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 50), (None,  11000       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 50), ( 10400       input_2[0][0]                    \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 1)      51          lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 21,451\n",
            "Trainable params: 21,451\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 70487 samples, validate on 9116 samples\n",
            "Epoch 1/100\n",
            "70487/70487 [==============================] - 10s 142us/sample - loss: 0.1728 - mean_squared_error: 0.0562 - val_loss: 0.1103 - val_mean_squared_error: 0.0234\n",
            "Epoch 2/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0876 - mean_squared_error: 0.0156 - val_loss: 0.0740 - val_mean_squared_error: 0.0106\n",
            "Epoch 3/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0665 - mean_squared_error: 0.0092 - val_loss: 0.0605 - val_mean_squared_error: 0.0071\n",
            "Epoch 4/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0567 - mean_squared_error: 0.0067 - val_loss: 0.0525 - val_mean_squared_error: 0.0054\n",
            "Epoch 5/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0512 - mean_squared_error: 0.0056 - val_loss: 0.0489 - val_mean_squared_error: 0.0047\n",
            "Epoch 6/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0482 - mean_squared_error: 0.0050 - val_loss: 0.0471 - val_mean_squared_error: 0.0044\n",
            "Epoch 7/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0463 - mean_squared_error: 0.0047 - val_loss: 0.0450 - val_mean_squared_error: 0.0040\n",
            "Epoch 8/100\n",
            "70487/70487 [==============================] - 5s 69us/sample - loss: 0.0451 - mean_squared_error: 0.0045 - val_loss: 0.0445 - val_mean_squared_error: 0.0040\n",
            "Epoch 9/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0440 - mean_squared_error: 0.0043 - val_loss: 0.0438 - val_mean_squared_error: 0.0038\n",
            "Epoch 10/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0432 - mean_squared_error: 0.0042 - val_loss: 0.0424 - val_mean_squared_error: 0.0037\n",
            "Epoch 11/100\n",
            "70487/70487 [==============================] - 5s 71us/sample - loss: 0.0425 - mean_squared_error: 0.0041 - val_loss: 0.0416 - val_mean_squared_error: 0.0035\n",
            "Epoch 12/100\n",
            "70487/70487 [==============================] - 5s 70us/sample - loss: 0.0418 - mean_squared_error: 0.0040 - val_loss: 0.0412 - val_mean_squared_error: 0.0035\n",
            "Epoch 13/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0413 - mean_squared_error: 0.0039 - val_loss: 0.0414 - val_mean_squared_error: 0.0036\n",
            "Epoch 14/100\n",
            "70487/70487 [==============================] - 5s 69us/sample - loss: 0.0409 - mean_squared_error: 0.0038 - val_loss: 0.0406 - val_mean_squared_error: 0.0034\n",
            "Epoch 15/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0408 - mean_squared_error: 0.0038 - val_loss: 0.0399 - val_mean_squared_error: 0.0033\n",
            "Epoch 16/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0405 - mean_squared_error: 0.0038 - val_loss: 0.0400 - val_mean_squared_error: 0.0033\n",
            "Epoch 17/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0404 - mean_squared_error: 0.0038 - val_loss: 0.0399 - val_mean_squared_error: 0.0033\n",
            "Epoch 18/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0401 - mean_squared_error: 0.0037 - val_loss: 0.0396 - val_mean_squared_error: 0.0033\n",
            "Epoch 19/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0399 - mean_squared_error: 0.0037 - val_loss: 0.0393 - val_mean_squared_error: 0.0033\n",
            "Epoch 20/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0396 - mean_squared_error: 0.0036 - val_loss: 0.0390 - val_mean_squared_error: 0.0032\n",
            "Epoch 21/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0394 - mean_squared_error: 0.0036 - val_loss: 0.0388 - val_mean_squared_error: 0.0032\n",
            "Epoch 22/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0392 - mean_squared_error: 0.0036 - val_loss: 0.0384 - val_mean_squared_error: 0.0031\n",
            "Epoch 23/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0390 - mean_squared_error: 0.0035 - val_loss: 0.0384 - val_mean_squared_error: 0.0031\n",
            "Epoch 24/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0388 - mean_squared_error: 0.0035 - val_loss: 0.0385 - val_mean_squared_error: 0.0031\n",
            "Epoch 25/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0387 - mean_squared_error: 0.0035 - val_loss: 0.0380 - val_mean_squared_error: 0.0030\n",
            "Epoch 26/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0385 - mean_squared_error: 0.0035 - val_loss: 0.0381 - val_mean_squared_error: 0.0031\n",
            "Epoch 27/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0383 - mean_squared_error: 0.0034 - val_loss: 0.0383 - val_mean_squared_error: 0.0031\n",
            "Epoch 28/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0381 - mean_squared_error: 0.0034 - val_loss: 0.0376 - val_mean_squared_error: 0.0030\n",
            "Epoch 29/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0380 - mean_squared_error: 0.0034 - val_loss: 0.0376 - val_mean_squared_error: 0.0030\n",
            "Epoch 30/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0378 - mean_squared_error: 0.0033 - val_loss: 0.0375 - val_mean_squared_error: 0.0030\n",
            "Epoch 31/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0377 - mean_squared_error: 0.0033 - val_loss: 0.0380 - val_mean_squared_error: 0.0030\n",
            "Epoch 32/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0376 - mean_squared_error: 0.0033 - val_loss: 0.0374 - val_mean_squared_error: 0.0029\n",
            "Epoch 33/100\n",
            "70487/70487 [==============================] - 5s 69us/sample - loss: 0.0375 - mean_squared_error: 0.0033 - val_loss: 0.0376 - val_mean_squared_error: 0.0030\n",
            "Epoch 34/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0373 - mean_squared_error: 0.0033 - val_loss: 0.0374 - val_mean_squared_error: 0.0029\n",
            "Epoch 35/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0373 - mean_squared_error: 0.0033 - val_loss: 0.0367 - val_mean_squared_error: 0.0029\n",
            "Epoch 36/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0372 - mean_squared_error: 0.0032 - val_loss: 0.0366 - val_mean_squared_error: 0.0028\n",
            "Epoch 37/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0370 - mean_squared_error: 0.0032 - val_loss: 0.0368 - val_mean_squared_error: 0.0029\n",
            "Epoch 38/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0371 - mean_squared_error: 0.0032 - val_loss: 0.0367 - val_mean_squared_error: 0.0029\n",
            "Epoch 39/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0369 - mean_squared_error: 0.0032 - val_loss: 0.0364 - val_mean_squared_error: 0.0028\n",
            "Epoch 40/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0368 - mean_squared_error: 0.0032 - val_loss: 0.0366 - val_mean_squared_error: 0.0028\n",
            "Epoch 41/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0366 - mean_squared_error: 0.0032 - val_loss: 0.0362 - val_mean_squared_error: 0.0028\n",
            "Epoch 42/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0365 - mean_squared_error: 0.0031 - val_loss: 0.0363 - val_mean_squared_error: 0.0028\n",
            "Epoch 43/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0363 - mean_squared_error: 0.0031 - val_loss: 0.0359 - val_mean_squared_error: 0.0028\n",
            "Epoch 44/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0362 - mean_squared_error: 0.0031 - val_loss: 0.0358 - val_mean_squared_error: 0.0027\n",
            "Epoch 45/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0360 - mean_squared_error: 0.0031 - val_loss: 0.0357 - val_mean_squared_error: 0.0027\n",
            "Epoch 46/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0359 - mean_squared_error: 0.0030 - val_loss: 0.0356 - val_mean_squared_error: 0.0027\n",
            "Epoch 47/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0358 - mean_squared_error: 0.0030 - val_loss: 0.0357 - val_mean_squared_error: 0.0027\n",
            "Epoch 48/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0357 - mean_squared_error: 0.0030 - val_loss: 0.0353 - val_mean_squared_error: 0.0027\n",
            "Epoch 49/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0356 - mean_squared_error: 0.0030 - val_loss: 0.0352 - val_mean_squared_error: 0.0026\n",
            "Epoch 50/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0354 - mean_squared_error: 0.0030 - val_loss: 0.0350 - val_mean_squared_error: 0.0026\n",
            "Epoch 51/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0353 - mean_squared_error: 0.0030 - val_loss: 0.0353 - val_mean_squared_error: 0.0026\n",
            "Epoch 52/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0353 - mean_squared_error: 0.0029 - val_loss: 0.0350 - val_mean_squared_error: 0.0026\n",
            "Epoch 53/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0352 - mean_squared_error: 0.0029 - val_loss: 0.0347 - val_mean_squared_error: 0.0026\n",
            "Epoch 54/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0351 - mean_squared_error: 0.0029 - val_loss: 0.0348 - val_mean_squared_error: 0.0026\n",
            "Epoch 55/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0350 - mean_squared_error: 0.0029 - val_loss: 0.0347 - val_mean_squared_error: 0.0026\n",
            "Epoch 56/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0349 - mean_squared_error: 0.0029 - val_loss: 0.0344 - val_mean_squared_error: 0.0025\n",
            "Epoch 57/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0348 - mean_squared_error: 0.0029 - val_loss: 0.0347 - val_mean_squared_error: 0.0026\n",
            "Epoch 58/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0348 - mean_squared_error: 0.0029 - val_loss: 0.0347 - val_mean_squared_error: 0.0025\n",
            "Epoch 59/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0347 - mean_squared_error: 0.0029 - val_loss: 0.0345 - val_mean_squared_error: 0.0025\n",
            "Epoch 60/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0347 - mean_squared_error: 0.0029 - val_loss: 0.0350 - val_mean_squared_error: 0.0026\n",
            "Epoch 61/100\n",
            "70487/70487 [==============================] - 5s 68us/sample - loss: 0.0346 - mean_squared_error: 0.0028 - val_loss: 0.0343 - val_mean_squared_error: 0.0025\n",
            "Epoch 62/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0345 - mean_squared_error: 0.0028 - val_loss: 0.0343 - val_mean_squared_error: 0.0025\n",
            "Epoch 63/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0344 - mean_squared_error: 0.0028 - val_loss: 0.0343 - val_mean_squared_error: 0.0025\n",
            "Epoch 64/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0344 - mean_squared_error: 0.0028 - val_loss: 0.0342 - val_mean_squared_error: 0.0025\n",
            "Epoch 65/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0342 - mean_squared_error: 0.0028 - val_loss: 0.0342 - val_mean_squared_error: 0.0025\n",
            "Epoch 66/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0341 - mean_squared_error: 0.0028 - val_loss: 0.0339 - val_mean_squared_error: 0.0025\n",
            "Epoch 67/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0340 - mean_squared_error: 0.0028 - val_loss: 0.0339 - val_mean_squared_error: 0.0025\n",
            "Epoch 68/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0338 - mean_squared_error: 0.0027 - val_loss: 0.0337 - val_mean_squared_error: 0.0024\n",
            "Epoch 69/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0337 - mean_squared_error: 0.0027 - val_loss: 0.0333 - val_mean_squared_error: 0.0024\n",
            "Epoch 70/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0336 - mean_squared_error: 0.0027 - val_loss: 0.0335 - val_mean_squared_error: 0.0024\n",
            "Epoch 71/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0336 - mean_squared_error: 0.0027 - val_loss: 0.0332 - val_mean_squared_error: 0.0024\n",
            "Epoch 72/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0334 - mean_squared_error: 0.0027 - val_loss: 0.0331 - val_mean_squared_error: 0.0023\n",
            "Epoch 73/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0333 - mean_squared_error: 0.0027 - val_loss: 0.0331 - val_mean_squared_error: 0.0023\n",
            "Epoch 74/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0333 - mean_squared_error: 0.0027 - val_loss: 0.0333 - val_mean_squared_error: 0.0023\n",
            "Epoch 75/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0333 - mean_squared_error: 0.0027 - val_loss: 0.0331 - val_mean_squared_error: 0.0023\n",
            "Epoch 76/100\n",
            "70487/70487 [==============================] - 5s 69us/sample - loss: 0.0333 - mean_squared_error: 0.0027 - val_loss: 0.0330 - val_mean_squared_error: 0.0024\n",
            "Epoch 77/100\n",
            "70487/70487 [==============================] - 5s 69us/sample - loss: 0.0332 - mean_squared_error: 0.0027 - val_loss: 0.0329 - val_mean_squared_error: 0.0023\n",
            "Epoch 78/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0331 - mean_squared_error: 0.0026 - val_loss: 0.0329 - val_mean_squared_error: 0.0023\n",
            "Epoch 79/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0331 - mean_squared_error: 0.0026 - val_loss: 0.0331 - val_mean_squared_error: 0.0024\n",
            "Epoch 80/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0331 - mean_squared_error: 0.0026 - val_loss: 0.0330 - val_mean_squared_error: 0.0023\n",
            "Epoch 81/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0331 - mean_squared_error: 0.0026 - val_loss: 0.0330 - val_mean_squared_error: 0.0023\n",
            "Epoch 82/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0331 - mean_squared_error: 0.0026 - val_loss: 0.0332 - val_mean_squared_error: 0.0023\n",
            "Epoch 83/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0331 - mean_squared_error: 0.0026 - val_loss: 0.0332 - val_mean_squared_error: 0.0023\n",
            "Epoch 84/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0330 - mean_squared_error: 0.0026 - val_loss: 0.0327 - val_mean_squared_error: 0.0023\n",
            "Epoch 85/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0330 - mean_squared_error: 0.0026 - val_loss: 0.0329 - val_mean_squared_error: 0.0023\n",
            "Epoch 86/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0330 - mean_squared_error: 0.0026 - val_loss: 0.0330 - val_mean_squared_error: 0.0023\n",
            "Epoch 87/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0330 - mean_squared_error: 0.0026 - val_loss: 0.0330 - val_mean_squared_error: 0.0023\n",
            "Epoch 88/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0329 - mean_squared_error: 0.0026 - val_loss: 0.0329 - val_mean_squared_error: 0.0023\n",
            "Epoch 89/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0329 - mean_squared_error: 0.0026 - val_loss: 0.0329 - val_mean_squared_error: 0.0023\n",
            "Epoch 90/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0329 - mean_squared_error: 0.0026 - val_loss: 0.0332 - val_mean_squared_error: 0.0023\n",
            "Epoch 91/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0328 - mean_squared_error: 0.0026 - val_loss: 0.0328 - val_mean_squared_error: 0.0023\n",
            "Epoch 92/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0328 - mean_squared_error: 0.0026 - val_loss: 0.0331 - val_mean_squared_error: 0.0023\n",
            "Epoch 93/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0328 - mean_squared_error: 0.0026 - val_loss: 0.0328 - val_mean_squared_error: 0.0023\n",
            "Epoch 94/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0328 - mean_squared_error: 0.0026 - val_loss: 0.0330 - val_mean_squared_error: 0.0023\n",
            "Epoch 95/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0328 - mean_squared_error: 0.0026 - val_loss: 0.0330 - val_mean_squared_error: 0.0024\n",
            "Epoch 96/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0328 - mean_squared_error: 0.0026 - val_loss: 0.0326 - val_mean_squared_error: 0.0023\n",
            "Epoch 97/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0327 - mean_squared_error: 0.0026 - val_loss: 0.0326 - val_mean_squared_error: 0.0023\n",
            "Epoch 98/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0327 - mean_squared_error: 0.0026 - val_loss: 0.0326 - val_mean_squared_error: 0.0023\n",
            "Epoch 99/100\n",
            "70487/70487 [==============================] - 5s 67us/sample - loss: 0.0327 - mean_squared_error: 0.0026 - val_loss: 0.0327 - val_mean_squared_error: 0.0023\n",
            "Epoch 100/100\n",
            "70487/70487 [==============================] - 5s 66us/sample - loss: 0.0327 - mean_squared_error: 0.0026 - val_loss: 0.0328 - val_mean_squared_error: 0.0023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgSImFJkV-Ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}